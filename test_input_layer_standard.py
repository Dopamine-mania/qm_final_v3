#!/usr/bin/env python3
"""
æµ‹è¯•è¾“å…¥å±‚æ ‡å‡†åŒ–æ¥å£å‡½æ•°
éªŒè¯æ ¹æ®ç”¨æˆ·è§„èŒƒæ·»åŠ çš„å››ä¸ªæ ‡å‡†åŒ–å‡½æ•°
"""

import sys
import os
import numpy as np
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from layers.input_layer import InputLayer, InputLayerConfig
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_input_layer_standard_functions():
    """æµ‹è¯•è¾“å…¥å±‚æ ‡å‡†åŒ–æ¥å£å‡½æ•°"""
    
    print("ğŸ“± è¾“å…¥å±‚æ ‡å‡†åŒ–æ¥å£å‡½æ•°æµ‹è¯•")
    print("=" * 60)
    
    # åˆå§‹åŒ–è¾“å…¥å±‚é…ç½®
    config = InputLayerConfig(
        layer_name="test_input_layer",
        text_enabled=True,
        audio_enabled=True,
        video_enabled=True,
        audio_chunk_size=1024,
        video_width=640,
        video_height=480
    )
    
    # åˆ›å»ºè¾“å…¥å±‚å®ä¾‹
    input_layer = InputLayer(config)
    
    print(f"âœ… è¾“å…¥å±‚åˆå§‹åŒ–å®Œæˆ")
    print(f"   â€¢ æ–‡æœ¬æ¨¡æ€: {'å¯ç”¨' if config.text_enabled else 'ç¦ç”¨'}")
    print(f"   â€¢ éŸ³é¢‘æ¨¡æ€: {'å¯ç”¨' if config.audio_enabled else 'ç¦ç”¨'}")
    print(f"   â€¢ è§†é¢‘æ¨¡æ€: {'å¯ç”¨' if config.video_enabled else 'ç¦ç”¨'}")
    
    # æµ‹è¯•1: capture_video_frame()
    print(f"\nğŸ“¹ æµ‹è¯•1: capture_video_frame() å‡½æ•°")
    print("=" * 40)
    
    try:
        video_frame = input_layer.capture_video_frame()
        print(f"âœ… è§†é¢‘å¸§æ•è·æˆåŠŸ")
        print(f"   â€¢ æ•°æ®ç±»å‹: {type(video_frame)}")
        print(f"   â€¢ æ•°ç»„å½¢çŠ¶: {video_frame.shape}")
        print(f"   â€¢ æ•°æ®ç±»å‹: {video_frame.dtype}")
        print(f"   â€¢ æ•°å€¼èŒƒå›´: [{video_frame.min()}, {video_frame.max()}]")
        
        # éªŒè¯é¢„æœŸæ ¼å¼
        if isinstance(video_frame, np.ndarray) and len(video_frame.shape) == 3:
            height, width, channels = video_frame.shape
            print(f"   âœ… æ ¼å¼éªŒè¯: {height}x{width}x{channels} (height x width x channels)")
        else:
            print(f"   âŒ æ ¼å¼é”™è¯¯: æœŸæœ›3ç»´æ•°ç»„")
            
    except Exception as e:
        print(f"âŒ è§†é¢‘å¸§æ•è·å¤±è´¥: {e}")
    
    # æµ‹è¯•2: capture_audio_chunk()
    print(f"\nğŸµ æµ‹è¯•2: capture_audio_chunk() å‡½æ•°")
    print("=" * 40)
    
    try:
        audio_chunk = input_layer.capture_audio_chunk()
        print(f"âœ… éŸ³é¢‘å—æ•è·æˆåŠŸ")
        print(f"   â€¢ æ•°æ®ç±»å‹: {type(audio_chunk)}")
        print(f"   â€¢ æ•°ç»„å½¢çŠ¶: {audio_chunk.shape}")
        print(f"   â€¢ æ•°æ®ç±»å‹: {audio_chunk.dtype}")
        print(f"   â€¢ æ•°å€¼èŒƒå›´: [{audio_chunk.min():.3f}, {audio_chunk.max():.3f}]")
        print(f"   â€¢ RMSèƒ½é‡: {np.sqrt(np.mean(audio_chunk**2)):.3f}")
        
        # éªŒè¯é¢„æœŸæ ¼å¼
        if isinstance(audio_chunk, np.ndarray) and len(audio_chunk.shape) == 1:
            print(f"   âœ… æ ¼å¼éªŒè¯: ä¸€ç»´éŸ³é¢‘æ•°ç»„ï¼Œé•¿åº¦ {len(audio_chunk)}")
        else:
            print(f"   âŒ æ ¼å¼é”™è¯¯: æœŸæœ›ä¸€ç»´æ•°ç»„")
            
    except Exception as e:
        print(f"âŒ éŸ³é¢‘å—æ•è·å¤±è´¥: {e}")
    
    # æµ‹è¯•3: get_user_text_input()
    print(f"\nğŸ“ æµ‹è¯•3: get_user_text_input() å‡½æ•°")
    print("=" * 40)
    
    try:
        # å…ˆæ·»åŠ ä¸€äº›æµ‹è¯•æ–‡æœ¬åˆ°ç¼“å†²åŒº
        test_texts = [
            "æˆ‘æ„Ÿåˆ°å¾ˆç„¦è™‘ï¼Œç¡ä¸ç€è§‰",
            "ä»Šå¤©å‹åŠ›å¾ˆå¤§ï¼Œéœ€è¦æ”¾æ¾",
            "å¿ƒæƒ…æ²®ä¸§ï¼Œæƒ³è¦å¹³é™ä¸‹æ¥"
        ]
        
        for text in test_texts:
            input_layer.add_text_input(text)
        
        # æµ‹è¯•å¤šæ¬¡è·å–æ–‡æœ¬è¾“å…¥
        for i in range(3):
            text_input = input_layer.get_user_text_input()
            print(f"âœ… æ–‡æœ¬è¾“å…¥è·å–æˆåŠŸ #{i+1}")
            print(f"   â€¢ æ•°æ®ç±»å‹: {type(text_input)}")
            print(f"   â€¢ æ–‡æœ¬é•¿åº¦: {len(text_input)}")
            print(f"   â€¢ å†…å®¹: {text_input}")
            
            # éªŒè¯é¢„æœŸæ ¼å¼
            if isinstance(text_input, str) and len(text_input) > 0:
                print(f"   âœ… æ ¼å¼éªŒè¯: éç©ºå­—ç¬¦ä¸²")
            else:
                print(f"   âŒ æ ¼å¼é”™è¯¯: æœŸæœ›éç©ºå­—ç¬¦ä¸²")
            print()
            
    except Exception as e:
        print(f"âŒ æ–‡æœ¬è¾“å…¥è·å–å¤±è´¥: {e}")
    
    # æµ‹è¯•4: collect_multimodal_data()
    print(f"\nğŸ”„ æµ‹è¯•4: collect_multimodal_data() ä¸»å‡½æ•°")
    print("=" * 40)
    
    try:
        multimodal_data = input_layer.collect_multimodal_data()
        print(f"âœ… å¤šæ¨¡æ€æ•°æ®æ”¶é›†æˆåŠŸ")
        
        # åˆ†ææ”¶é›†åˆ°çš„æ•°æ®ç»“æ„
        print(f"\nğŸ“Š æ•°æ®ç»“æ„åˆ†æ:")
        
        # è§†é¢‘æ•°æ®åˆ†æ
        video_data = multimodal_data.get('video', {})
        print(f"   ğŸ“¹ è§†é¢‘æ•°æ®:")
        print(f"      â€¢ å¯ç”¨çŠ¶æ€: {video_data.get('enabled', False)}")
        if video_data.get('raw_frame') is not None:
            raw_frame = video_data['raw_frame']
            print(f"      â€¢ åŸå§‹å¸§å½¢çŠ¶: {raw_frame.shape}")
            print(f"      â€¢ å¤„ç†çŠ¶æ€: {'å·²å¤„ç†' if video_data.get('processed') else 'æœªå¤„ç†'}")
        
        # éŸ³é¢‘æ•°æ®åˆ†æ
        audio_data = multimodal_data.get('audio', {})
        print(f"   ğŸµ éŸ³é¢‘æ•°æ®:")
        print(f"      â€¢ å¯ç”¨çŠ¶æ€: {audio_data.get('enabled', False)}")
        if audio_data.get('raw_chunk') is not None:
            raw_chunk = audio_data['raw_chunk']
            print(f"      â€¢ åŸå§‹éŸ³é¢‘é•¿åº¦: {len(raw_chunk)}")
            print(f"      â€¢ å¤„ç†çŠ¶æ€: {'å·²å¤„ç†' if audio_data.get('processed') else 'æœªå¤„ç†'}")
        
        # æ–‡æœ¬æ•°æ®åˆ†æ
        text_data = multimodal_data.get('text', {})
        print(f"   ğŸ“ æ–‡æœ¬æ•°æ®:")
        print(f"      â€¢ å¯ç”¨çŠ¶æ€: {text_data.get('enabled', False)}")
        if text_data.get('raw_text'):
            raw_text = text_data['raw_text']
            print(f"      â€¢ åŸå§‹æ–‡æœ¬: {raw_text}")
            print(f"      â€¢ å¤„ç†çŠ¶æ€: {'å·²å¤„ç†' if text_data.get('processed') else 'æœªå¤„ç†'}")
        
        # å…ƒæ•°æ®åˆ†æ
        metadata = multimodal_data.get('metadata', {})
        print(f"   ğŸ“‹ å…ƒæ•°æ®:")
        print(f"      â€¢ æ”¶é›†æ—¶é—´: {metadata.get('collection_timestamp')}")
        print(f"      â€¢ æ”¶é›†æ¨¡å¼: {metadata.get('collection_mode')}")
        print(f"      â€¢ æ•°æ®è´¨é‡: {metadata.get('data_quality', 0):.3f}")
        
        enabled_modalities = metadata.get('enabled_modalities', {})
        enabled_count = sum([1 for enabled in enabled_modalities.values() if enabled])
        print(f"      â€¢ å¯ç”¨æ¨¡æ€æ•°: {enabled_count}/3")
        
        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        required_keys = ['video', 'audio', 'text', 'metadata']
        missing_keys = [key for key in required_keys if key not in multimodal_data]
        
        if not missing_keys:
            print(f"   âœ… æ•°æ®å®Œæ•´æ€§: æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨")
        else:
            print(f"   âŒ æ•°æ®å®Œæ•´æ€§: ç¼ºå°‘å­—æ®µ {missing_keys}")
            
    except Exception as e:
        print(f"âŒ å¤šæ¨¡æ€æ•°æ®æ”¶é›†å¤±è´¥: {e}")
    
    # æ€§èƒ½æµ‹è¯•
    print(f"\nâš¡ æ€§èƒ½æµ‹è¯•")
    print("=" * 30)
    
    import time
    
    # æµ‹è¯•å•æ¬¡è°ƒç”¨æ€§èƒ½
    performance_tests = [
        ("capture_video_frame", lambda: input_layer.capture_video_frame()),
        ("capture_audio_chunk", lambda: input_layer.capture_audio_chunk()),
        ("get_user_text_input", lambda: input_layer.get_user_text_input()),
        ("collect_multimodal_data", lambda: input_layer.collect_multimodal_data())
    ]
    
    for test_name, test_func in performance_tests:
        start_time = time.time()
        try:
            result = test_func()
            end_time = time.time()
            execution_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            print(f"   â€¢ {test_name}: {execution_time:.2f}ms âœ…")
        except Exception as e:
            end_time = time.time()
            execution_time = (end_time - start_time) * 1000
            print(f"   â€¢ {test_name}: {execution_time:.2f}ms âŒ ({e})")
    
    # æ‰¹é‡æµ‹è¯•
    print(f"\nğŸ“¦ æ‰¹é‡è°ƒç”¨æµ‹è¯• (10æ¬¡)")
    print("=" * 30)
    
    batch_size = 10
    start_time = time.time()
    
    try:
        for i in range(batch_size):
            multimodal_data = input_layer.collect_multimodal_data()
        
        end_time = time.time()
        total_time = (end_time - start_time) * 1000
        avg_time = total_time / batch_size
        
        print(f"   â€¢ æ€»æ—¶é—´: {total_time:.2f}ms")
        print(f"   â€¢ å¹³å‡æ—¶é—´: {avg_time:.2f}ms")
        print(f"   â€¢ ååé‡: {1000/avg_time:.1f} æ¬¡/ç§’")
        
    except Exception as e:
        print(f"   âŒ æ‰¹é‡æµ‹è¯•å¤±è´¥: {e}")
    
    # æ¸…ç†èµ„æº
    input_layer.shutdown()
    
    print(f"\nğŸ‰ è¾“å…¥å±‚æ ‡å‡†åŒ–æ¥å£å‡½æ•°æµ‹è¯•å®Œæˆï¼")
    print(f"\nğŸ“Š æµ‹è¯•æ€»ç»“:")
    print(f"   âœ… capture_video_frame() - è§†é¢‘å¸§æ•è·æ¨¡æ‹Ÿ")
    print(f"   âœ… capture_audio_chunk() - éŸ³é¢‘å—æ•è·æ¨¡æ‹Ÿ") 
    print(f"   âœ… get_user_text_input() - æ–‡æœ¬è¾“å…¥æ¨¡æ‹Ÿ")
    print(f"   âœ… collect_multimodal_data() - å¤šæ¨¡æ€æ•°æ®æ”¶é›†ä¸»å‡½æ•°")
    print(f"\nğŸ’¡ æ ¸å¿ƒç‰¹æ€§:")
    print(f"   â€¢ ä¼ æ„Ÿå™¨æ•°æ®æ•è·æ¨¡æ‹Ÿ")
    print(f"   â€¢ åŸå§‹æ•°æ®å¤„ç†å’Œé¢„å¤„ç†")
    print(f"   â€¢ å¤šæ¨¡æ€æ•°æ®åŒæ­¥æ”¶é›†")
    print(f"   â€¢ æ•°æ®è´¨é‡è¯„ä¼°å’Œç›‘æ§")
    print(f"   â€¢ é”™è¯¯å¤„ç†å’Œæ¨¡æ‹Ÿæ•°æ®å›é€€")

if __name__ == "__main__":
    test_input_layer_standard_functions()