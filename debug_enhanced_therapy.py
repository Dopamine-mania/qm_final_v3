#!/usr/bin/env python3
"""
ğŸ” è°ƒè¯•ç‰ˆå¢å¼ºç–—æ„ˆç³»ç»Ÿ
æ‰¾å‡ºåŸç‰ˆæœ¬å¡é¡¿çš„åŸå› 
"""

import numpy as np
import sys
import os
import time
from pathlib import Path

def debug_step(step_name, func, *args, **kwargs):
    """è°ƒè¯•æ­¥éª¤åŒ…è£…å™¨"""
    print(f"ğŸ” å¼€å§‹: {step_name}")
    start_time = time.time()
    try:
        result = func(*args, **kwargs)
        end_time = time.time()
        print(f"âœ… å®Œæˆ: {step_name} - è€—æ—¶: {end_time - start_time:.2f}ç§’")
        return result
    except Exception as e:
        end_time = time.time()
        print(f"âŒ é”™è¯¯: {step_name} - è€—æ—¶: {end_time - start_time:.2f}ç§’")
        print(f"   é”™è¯¯ä¿¡æ¯: {e}")
        raise

def debug_generate_audio(duration=20, sample_rate=44100, emotion="ç„¦è™‘"):
    """è°ƒè¯•éŸ³é¢‘ç”Ÿæˆè¿‡ç¨‹"""
    print(f"ğŸµ è°ƒè¯•éŸ³é¢‘ç”Ÿæˆ: {duration}ç§’, {sample_rate}Hz, {emotion}")
    
    # æ­¥éª¤1: å‚æ•°è®¾ç½®
    def setup_params():
        emotion_params = {
            "ç„¦è™‘": {
                "sync_freq": 440, "guide_freq": 330, "consolidate_freq": 220,
                "sync_intensity": 0.4, "guide_intensity": 0.25, "consolidate_intensity": 0.15,
                "transition_type": "exponential"
            }
        }
        return emotion_params.get(emotion, emotion_params["ç„¦è™‘"])
    
    params = debug_step("å‚æ•°è®¾ç½®", setup_params)
    
    # æ­¥éª¤2: åˆ›å»ºéŸ³é¢‘æ•°ç»„
    def create_audio_array():
        total_samples = int(sample_rate * duration)
        print(f"   æ€»æ ·æœ¬æ•°: {total_samples:,}")
        if total_samples > 2000000:  # è¶…è¿‡200ä¸‡æ ·æœ¬
            print("   âš ï¸ è­¦å‘Š: æ ·æœ¬æ•°è¿‡å¤šï¼Œå¯èƒ½å¯¼è‡´å†…å­˜é—®é¢˜")
        audio_array = np.zeros(total_samples)
        return audio_array, total_samples
    
    audio_array, total_samples = debug_step("åˆ›å»ºéŸ³é¢‘æ•°ç»„", create_audio_array)
    
    # æ­¥éª¤3: ç”Ÿæˆæ—¶é—´è½´
    def create_timeline():
        t_total = np.linspace(0, duration, total_samples)
        return t_total
    
    t_total = debug_step("ç”Ÿæˆæ—¶é—´è½´", create_timeline)
    
    # æ­¥éª¤4: ç¬¬ä¸€é˜¶æ®µéŸ³é¢‘
    def generate_stage1():
        stage1_duration = duration * 0.3
        stage1_mask = t_total <= stage1_duration
        stage1_time = t_total[stage1_mask]
        print(f"   ç¬¬ä¸€é˜¶æ®µæ ·æœ¬æ•°: {len(stage1_time):,}")
        
        stage1_audio = params['sync_intensity'] * np.sin(2 * np.pi * params['sync_freq'] * stage1_time)
        
        # æ·»åŠ ç„¦è™‘ç‰¹å¾
        if emotion == "ç„¦è™‘":
            tremolo = 0.1 * np.sin(2 * np.pi * 5 * stage1_time)
            stage1_audio *= (1 + tremolo)
        
        audio_array[stage1_mask] = stage1_audio
        return stage1_duration
    
    stage1_duration = debug_step("ç¬¬ä¸€é˜¶æ®µéŸ³é¢‘", generate_stage1)
    
    # æ­¥éª¤5: ç¬¬äºŒé˜¶æ®µéŸ³é¢‘ï¼ˆæœ€å¤æ‚ï¼‰
    def generate_stage2():
        stage2_duration = duration * 0.4
        stage2_start = stage1_duration
        stage2_end = stage2_start + stage2_duration
        stage2_mask = (t_total > stage2_start) & (t_total <= stage2_end)
        stage2_time = t_total[stage2_mask] - stage2_start
        print(f"   ç¬¬äºŒé˜¶æ®µæ ·æœ¬æ•°: {len(stage2_time):,}")
        
        # è¿‡æ¸¡è®¡ç®—
        transition_progress = stage2_time / stage2_duration
        
        # é€‰æ‹©è¿‡æ¸¡å‡½æ•°
        if params['transition_type'] == "exponential":
            transition_curve = 1 - np.exp(-3 * transition_progress)
        else:
            transition_curve = transition_progress
        
        # åŠ¨æ€é¢‘ç‡å˜åŒ–
        current_freq = params['sync_freq'] + (params['guide_freq'] - params['sync_freq']) * transition_curve
        current_intensity = params['sync_intensity'] + (params['guide_intensity'] - params['sync_intensity']) * transition_curve
        
        stage2_audio = current_intensity * np.sin(2 * np.pi * current_freq * stage2_time)
        
        # æ·»åŠ å’Œè°æ³›éŸ³
        harmonic1 = 0.3 * current_intensity * np.sin(2 * np.pi * current_freq * 2 * stage2_time)
        harmonic2 = 0.2 * current_intensity * np.sin(2 * np.pi * current_freq * 3 * stage2_time)
        stage2_audio += harmonic1 + harmonic2
        
        audio_array[stage2_mask] = stage2_audio
        return stage2_end
    
    stage2_end = debug_step("ç¬¬äºŒé˜¶æ®µéŸ³é¢‘", generate_stage2)
    
    # æ­¥éª¤6: ç¬¬ä¸‰é˜¶æ®µéŸ³é¢‘
    def generate_stage3():
        stage3_mask = t_total > stage2_end
        stage3_time = t_total[stage3_mask] - stage2_end
        print(f"   ç¬¬ä¸‰é˜¶æ®µæ ·æœ¬æ•°: {len(stage3_time):,}")
        
        # é¢‘ç‡è¿‡æ¸¡
        consolidate_transition = np.exp(-stage3_time / 3)
        final_freq = params['guide_freq'] + (params['consolidate_freq'] - params['guide_freq']) * (1 - consolidate_transition)
        final_intensity = params['consolidate_intensity'] * np.exp(-stage3_time / 10)
        
        stage3_audio = final_intensity * np.sin(2 * np.pi * final_freq * stage3_time)
        
        # æ·»åŠ è‡ªç„¶éŸ³æ•ˆ
        nature_sound = 0.05 * np.random.normal(0, 1, len(stage3_time))
        wave_sound = 0.1 * final_intensity * np.sin(2 * np.pi * 0.3 * stage3_time)
        stage3_audio += nature_sound + wave_sound
        
        audio_array[stage3_mask] = stage3_audio
    
    debug_step("ç¬¬ä¸‰é˜¶æ®µéŸ³é¢‘", generate_stage3)
    
    # æ­¥éª¤7: ç«‹ä½“å£°å¤„ç†
    def create_stereo():
        left_channel = audio_array.copy()
        right_channel = audio_array.copy()
        
        # ç«‹ä½“å£°å»¶è¿Ÿ
        stereo_delay = int(0.01 * sample_rate)
        print(f"   ç«‹ä½“å£°å»¶è¿Ÿæ ·æœ¬æ•°: {stereo_delay}")
        
        if len(right_channel) > stereo_delay:
            right_channel[stereo_delay:] = audio_array[:-stereo_delay]
        
        # æ··å“ï¼ˆå¯èƒ½æ˜¯æ€§èƒ½ç“¶é¢ˆï¼‰
        print(f"   å¼€å§‹æ··å“è®¡ç®—...")
        reverb_length = int(0.5 * sample_rate)
        print(f"   æ··å“é•¿åº¦: {reverb_length}")
        
        # è¿™é‡Œå¯èƒ½æ˜¯å¡é¡¿çš„åŸå› 
        reverb_impulse = np.exp(-np.linspace(0, 2, reverb_length))
        reverb = 0.1 * np.convolve(audio_array, reverb_impulse, mode='same')
        print(f"   æ··å“è®¡ç®—å®Œæˆ")
        
        left_channel += reverb
        right_channel += reverb * 0.8
        
        stereo_audio = np.column_stack([left_channel, right_channel])
        
        # å½’ä¸€åŒ–
        stereo_audio = stereo_audio / np.max(np.abs(stereo_audio)) * 0.8
        
        return stereo_audio
    
    stereo_audio = debug_step("ç«‹ä½“å£°å¤„ç†", create_stereo)
    
    # æ­¥éª¤8: æ·¡å…¥æ·¡å‡º
    def apply_fade():
        fade_samples = int(0.5 * sample_rate)
        print(f"   æ·¡å…¥æ·¡å‡ºæ ·æœ¬æ•°: {fade_samples}")
        
        fade_in = np.linspace(0, 1, fade_samples)
        fade_out = np.linspace(1, 0, fade_samples)
        
        stereo_audio[:fade_samples] *= fade_in[:, np.newaxis]
        stereo_audio[-fade_samples:] *= fade_out[:, np.newaxis]
        
        return stereo_audio.astype(np.float32)
    
    final_audio = debug_step("æ·¡å…¥æ·¡å‡º", apply_fade)
    
    return final_audio, sample_rate, params

def main():
    """ä¸»å‡½æ•° - è°ƒè¯•ç‰ˆæœ¬"""
    print("ğŸ” å¯åŠ¨è°ƒè¯•ç‰ˆå¢å¼ºç–—æ„ˆç³»ç»Ÿ...")
    print("ğŸ¯ ç›®æ ‡ï¼šæ‰¾å‡ºæ€§èƒ½ç“¶é¢ˆå’Œå¡é¡¿åŸå› ")
    print("=" * 50)
    
    # æµ‹è¯•ä¸åŒå‚æ•°
    test_cases = [
        {"duration": 5, "sample_rate": 22050, "name": "è½»é‡çº§æµ‹è¯•"},
        {"duration": 10, "sample_rate": 44100, "name": "æ ‡å‡†æµ‹è¯•"},
        {"duration": 20, "sample_rate": 44100, "name": "å®Œæ•´æµ‹è¯•"}
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ§ª æµ‹è¯•ç”¨ä¾‹ {i}: {test_case['name']}")
        print(f"   å‚æ•°: {test_case['duration']}ç§’, {test_case['sample_rate']}Hz")
        
        try:
            start_time = time.time()
            audio_array, sample_rate, params = debug_generate_audio(
                duration=test_case['duration'],
                sample_rate=test_case['sample_rate'],
                emotion="ç„¦è™‘"
            )
            total_time = time.time() - start_time
            
            print(f"âœ… æµ‹è¯•ç”¨ä¾‹ {i} å®Œæˆ")
            print(f"   æ€»è€—æ—¶: {total_time:.2f}ç§’")
            print(f"   éŸ³é¢‘å½¢çŠ¶: {audio_array.shape}")
            print(f"   å†…å­˜å ç”¨: {audio_array.nbytes / 1024 / 1024:.1f}MB")
            
            # ä¿å­˜è°ƒè¯•éŸ³é¢‘
            output_dir = Path("outputs")
            output_dir.mkdir(exist_ok=True)
            
            try:
                from scipy.io import wavfile
                audio_path = output_dir / f"debug_{test_case['name'].replace(' ', '_')}.wav"
                audio_int = (audio_array * 32767).astype(np.int16)
                wavfile.write(str(audio_path), sample_rate, audio_int)
                print(f"   ä¿å­˜è‡³: {audio_path}")
            except ImportError:
                print("   scipyæœªå®‰è£…ï¼Œè·³è¿‡ä¿å­˜")
            
        except KeyboardInterrupt:
            print(f"\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æµ‹è¯•ç”¨ä¾‹ {i}")
            break
        except Exception as e:
            print(f"âŒ æµ‹è¯•ç”¨ä¾‹ {i} å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print("\nğŸ” è°ƒè¯•å®Œæˆ!")
    print("ğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
    print("   1. é™ä½é‡‡æ ·ç‡ (44100 â†’ 22050)")
    print("   2. å‡å°‘éŸ³é¢‘æ—¶é•¿ (20s â†’ 10s)")
    print("   3. ç®€åŒ–æ··å“è®¡ç®—")
    print("   4. ä¼˜åŒ–å’Œè°æ³›éŸ³ç”Ÿæˆ")

if __name__ == "__main__":
    main()