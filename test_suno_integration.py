#!/usr/bin/env python3
"""
æµ‹è¯•Suno APIé›†æˆ
å¿«é€ŸéªŒè¯ä¸‰é˜¶æ®µéŸ³ä¹å™äº‹ç”ŸæˆåŠŸèƒ½
"""

import sys
import asyncio
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from layers.generation_layer import GenerationLayer, GenerationLayerConfig, MusicParameter
from layers.base_layer import LayerData
from datetime import datetime
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

async def test_suno_integration():
    """æµ‹è¯•Suno APIé›†æˆ"""
    
    logger.info("ğŸš€ å¼€å§‹æµ‹è¯•Suno APIé›†æˆ...")
    
    # åˆ›å»ºç”Ÿæˆå±‚é…ç½®
    config = GenerationLayerConfig(
        layer_name="test_generation_layer",
        audio_enabled=True,
        video_enabled=False,  # å…ˆåªæµ‹è¯•éŸ³é¢‘
        audio_duration=120.0,  # 2åˆ†é’Ÿ
        generation_strategy="hybrid"
    )
    
    # åˆå§‹åŒ–ç”Ÿæˆå±‚
    generation_layer = GenerationLayer(config)
    
    # æ¨¡æ‹Ÿä»èåˆå±‚æ¥çš„æƒ…ç»ªæ•°æ®å’Œæ˜ å°„å±‚çš„éŸ³ä¹å‚æ•°
    test_input_data = LayerData(
        layer_name="test_input",
        timestamp=datetime.now(),
        data={
            'emotion_analysis': {
                'primary_emotion': {'name': 'ç„¦è™‘', 'confidence': 0.85},
                'emotion_vector': [0.2, 0.8, -0.3, 0.1]  # ç¤ºä¾‹27ç»´å‘é‡çš„ä¸€éƒ¨åˆ†
            },
            'music_parameters': {
                'tempo_bpm': 80.0,
                'key_signature': 'C_major',
                'valence_mapping': -0.3,  # è´Ÿé¢æƒ…ç»ª
                'arousal_mapping': 0.6,   # é«˜å”¤é†’
                'iso_stage': 'synchronization'
            }
        },
        metadata={'test_run': True},
        confidence=0.85
    )
    
    try:
        # æµ‹è¯•ç”Ÿæˆè¿‡ç¨‹
        logger.info("ğŸµ å¼€å§‹ç”Ÿæˆä¸‰é˜¶æ®µéŸ³ä¹...")
        result = await generation_layer._process_impl(test_input_data)
        
        # æ£€æŸ¥ç»“æœ
        if result.data.get('error'):
            logger.error(f"âŒ ç”Ÿæˆå¤±è´¥: {result.data['error']}")
            return False
        
        generated_content = result.data.get('generated_content', {})
        audio_content = generated_content.get('audio', {})
        
        if 'error' in audio_content:
            logger.error(f"âŒ éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {audio_content['error']}")
            return False
        
        # è¾“å‡ºç»“æœä¿¡æ¯
        logger.info("âœ… ç”ŸæˆæˆåŠŸï¼")
        logger.info(f"   æ—¶é•¿: {audio_content.get('duration', 0)}ç§’")
        logger.info(f"   é‡‡æ ·ç‡: {audio_content.get('sample_rate', 0)}Hz")
        logger.info(f"   å£°é“æ•°: {audio_content.get('channels', 0)}")
        logger.info(f"   ä¸‰é˜¶æ®µå™äº‹: {audio_content.get('three_stage_narrative', False)}")
        logger.info(f"   ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ: {audio_content.get('fallback_used', 'æœªçŸ¥')}")
        
        # æ˜¾ç¤ºé˜¶æ®µæç¤ºè¯ï¼ˆå¦‚æœæœ‰ï¼‰
        stage_prompts = audio_content.get('stage_prompts', {})
        if stage_prompts:
            logger.info("ğŸ“ ç”Ÿæˆçš„é˜¶æ®µæç¤ºè¯:")
            for stage, prompt in stage_prompts.items():
                logger.info(f"   {stage}: {prompt[:100]}...")
        
        # æ£€æŸ¥éŸ³é¢‘æ•°ç»„
        audio_array = audio_content.get('audio_array')
        if audio_array is not None:
            logger.info(f"   éŸ³é¢‘æ•°ç»„å½¢çŠ¶: {audio_array.shape}")
            logger.info(f"   éŸ³é¢‘æ•°æ®ç±»å‹: {audio_array.dtype}")
        
        logger.info("ğŸ‰ Suno APIé›†æˆæµ‹è¯•å®Œæˆï¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_multiple_emotions():
    """æµ‹è¯•å¤šç§æƒ…ç»ªåœºæ™¯"""
    
    test_emotions = [
        {'name': 'ç„¦è™‘', 'valence': -0.3, 'arousal': 0.6},
        {'name': 'ç–²æƒ«', 'valence': -0.1, 'arousal': -0.4},
        {'name': 'ä¸­æ€§', 'valence': 0.0, 'arousal': 0.0},
        {'name': 'çƒ¦èº', 'valence': -0.5, 'arousal': 0.8},
    ]
    
    logger.info(f"ğŸ­ æµ‹è¯•{len(test_emotions)}ç§ä¸åŒæƒ…ç»ªåœºæ™¯...")
    
    # åˆ›å»ºç”Ÿæˆå±‚
    config = GenerationLayerConfig(
        layer_name="multi_emotion_test_layer",
        audio_enabled=True,
        video_enabled=False,
        audio_duration=60.0  # ç¼©çŸ­åˆ°1åˆ†é’ŸåŠ å¿«æµ‹è¯•
    )
    generation_layer = GenerationLayer(config)
    
    success_count = 0
    
    for i, emotion in enumerate(test_emotions, 1):
        logger.info(f"ğŸ”„ æµ‹è¯•åœºæ™¯ {i}/{len(test_emotions)}: {emotion['name']}")
        
        test_data = LayerData(
            layer_name="emotion_test",
            timestamp=datetime.now(),
            data={
                'emotion_analysis': {
                    'primary_emotion': {'name': emotion['name'], 'confidence': 0.80},
                },
                'music_parameters': {
                    'tempo_bpm': 70.0,
                    'valence_mapping': emotion['valence'],
                    'arousal_mapping': emotion['arousal'],
                }
            },
            metadata={'emotion_test': True},
            confidence=0.80
        )
        
        try:
            result = await generation_layer._process_impl(test_data)
            
            if not result.data.get('error'):
                audio_content = result.data.get('generated_content', {}).get('audio', {})
                if 'error' not in audio_content:
                    success_count += 1
                    logger.info(f"   âœ… {emotion['name']} - ç”ŸæˆæˆåŠŸ")
                else:
                    logger.warning(f"   âš ï¸ {emotion['name']} - éŸ³é¢‘ç”Ÿæˆå¤±è´¥")
            else:
                logger.warning(f"   âš ï¸ {emotion['name']} - å¤„ç†å¤±è´¥")
                
        except Exception as e:
            logger.error(f"   âŒ {emotion['name']} - å¼‚å¸¸: {e}")
    
    logger.info(f"ğŸ¯ å¤šæƒ…ç»ªæµ‹è¯•å®Œæˆ: {success_count}/{len(test_emotions)} æˆåŠŸ")
    return success_count == len(test_emotions)

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸ§ª å¼€å§‹Suno APIé›†æˆæµ‹è¯•å¥—ä»¶...")
    
    # åŸºç¡€åŠŸèƒ½æµ‹è¯•
    test1_result = await test_suno_integration()
    
    # å¤šæƒ…ç»ªåœºæ™¯æµ‹è¯•
    test2_result = await test_multiple_emotions()
    
    # æ±‡æ€»ç»“æœ
    if test1_result and test2_result:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Suno APIé›†æˆæˆåŠŸï¼")
        logger.info("ğŸ’¡ ä¸‹ä¸€æ­¥å¯ä»¥:")
        logger.info("   1. è·å–çœŸå®çš„Suno APIå¯†é’¥")
        logger.info("   2. æ›¿æ¢_simulate_suno_responseä¸ºçœŸå®APIè°ƒç”¨")
        logger.info("   3. æµ‹è¯•å®Œæ•´çš„ç«¯åˆ°ç«¯æµç¨‹")
        return True
    else:
        logger.error("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥é—®é¢˜")
        return False

if __name__ == "__main__":
    result = asyncio.run(main())
    sys.exit(0 if result else 1)