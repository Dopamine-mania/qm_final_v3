#!/usr/bin/env python3
"""
ğŸŒ™ è½»é‡çº§å¢å¼ºä¸‰é˜¶æ®µç–—æ„ˆç³»ç»Ÿ
ä¼˜åŒ–æ€§èƒ½ï¼Œé¿å…å¡é¡¿ï¼Œå¿«é€Ÿå“åº”
"""

import numpy as np
import sys
import os
import time
from pathlib import Path

def generate_lightweight_therapy_audio(duration=10, sample_rate=22050, emotion="ç„¦è™‘"):
    """ç”Ÿæˆè½»é‡çº§ç–—æ„ˆéŸ³é¢‘ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
    print(f"ğŸµ ç”Ÿæˆ{duration}ç§’è½»é‡çº§ç–—æ„ˆéŸ³é¢‘ (é’ˆå¯¹{emotion}æƒ…ç»ª)")
    
    # å‡å°‘é‡‡æ ·ç‡å’Œæ—¶é•¿ä»¥æå‡æ€§èƒ½
    duration = min(duration, 15)  # æœ€å¤§15ç§’
    sample_rate = 22050  # é™ä½é‡‡æ ·ç‡
    
    # ç®€åŒ–çš„æƒ…ç»ªå‚æ•°
    emotion_params = {
        "ç„¦è™‘": {"sync_freq": 440, "guide_freq": 330, "consolidate_freq": 220},
        "ç–²æƒ«": {"sync_freq": 380, "guide_freq": 280, "consolidate_freq": 200},
        "çƒ¦èº": {"sync_freq": 460, "guide_freq": 350, "consolidate_freq": 240},
        "å¹³é™": {"sync_freq": 400, "guide_freq": 320, "consolidate_freq": 210},
        "å‹åŠ›": {"sync_freq": 480, "guide_freq": 360, "consolidate_freq": 230}
    }
    
    params = emotion_params.get(emotion, emotion_params["ç„¦è™‘"])
    
    # ä¸‰é˜¶æ®µæ—¶é—´åˆ†é…
    stage1_duration = duration * 0.3
    stage2_duration = duration * 0.4
    stage3_duration = duration * 0.3
    
    print(f"ğŸµ ä¸‰é˜¶æ®µæ—¶é•¿: åŒæ­¥æœŸ{stage1_duration:.1f}s â†’ å¼•å¯¼æœŸ{stage2_duration:.1f}s â†’ å·©å›ºæœŸ{stage3_duration:.1f}s")
    
    # ç”ŸæˆéŸ³é¢‘æ•°ç»„ï¼ˆç®€åŒ–ç‰ˆï¼‰
    total_samples = int(sample_rate * duration)
    audio_mono = np.zeros(total_samples)
    
    # æ—¶é—´è½´
    t = np.linspace(0, duration, total_samples)
    
    # ç¬¬ä¸€é˜¶æ®µï¼šåŒæ­¥æœŸ
    stage1_mask = t <= stage1_duration
    stage1_audio = 0.3 * np.sin(2 * np.pi * params['sync_freq'] * t[stage1_mask])
    audio_mono[stage1_mask] = stage1_audio
    
    # ç¬¬äºŒé˜¶æ®µï¼šå¼•å¯¼æœŸï¼ˆç®€åŒ–çš„çº¿æ€§è¿‡æ¸¡ï¼‰
    stage2_mask = (t > stage1_duration) & (t <= stage1_duration + stage2_duration)
    stage2_t = t[stage2_mask] - stage1_duration
    transition_progress = stage2_t / stage2_duration
    
    # çº¿æ€§é¢‘ç‡è¿‡æ¸¡
    current_freq = params['sync_freq'] + (params['guide_freq'] - params['sync_freq']) * transition_progress
    stage2_audio = 0.25 * np.sin(2 * np.pi * current_freq * stage2_t)
    audio_mono[stage2_mask] = stage2_audio
    
    # ç¬¬ä¸‰é˜¶æ®µï¼šå·©å›ºæœŸ
    stage3_mask = t > stage1_duration + stage2_duration
    stage3_t = t[stage3_mask] - stage1_duration - stage2_duration
    stage3_audio = 0.15 * np.sin(2 * np.pi * params['consolidate_freq'] * stage3_t)
    # æ·»åŠ ç®€å•çš„è¡°å‡
    stage3_audio *= np.exp(-stage3_t / 8)
    audio_mono[stage3_mask] = stage3_audio
    
    # ç®€åŒ–çš„ç«‹ä½“å£°å¤„ç†
    stereo_audio = np.column_stack([audio_mono, audio_mono])
    
    # å½’ä¸€åŒ–
    stereo_audio = stereo_audio / np.max(np.abs(stereo_audio) + 1e-10) * 0.7
    
    # ç®€åŒ–çš„æ·¡å…¥æ·¡å‡º
    fade_samples = int(0.1 * sample_rate)  # 0.1ç§’æ·¡å…¥æ·¡å‡º
    if fade_samples > 0:
        fade_in = np.linspace(0, 1, fade_samples)
        fade_out = np.linspace(1, 0, fade_samples)
        stereo_audio[:fade_samples] *= fade_in[:, np.newaxis]
        if len(stereo_audio) > fade_samples:
            stereo_audio[-fade_samples:] *= fade_out[:, np.newaxis]
    
    return stereo_audio.astype(np.float32), sample_rate, params

def save_audio_simple(audio_array, sample_rate, output_path):
    """ç®€åŒ–çš„éŸ³é¢‘ä¿å­˜"""
    try:
        # å°è¯•ä½¿ç”¨scipy
        from scipy.io import wavfile
        audio_int = (audio_array * 32767).astype(np.int16)
        wavfile.write(output_path, sample_rate, audio_int)
        return True
    except ImportError:
        # ä¿å­˜ä¸ºnumpyæ•°ç»„
        np.save(output_path.replace('.wav', '.npy'), audio_array)
        return False

def detect_emotion_simple(user_input):
    """ç®€åŒ–çš„æƒ…ç»ªæ£€æµ‹"""
    emotion_keywords = {
        "ç„¦è™‘": ["ç„¦è™‘", "ç´§å¼ ", "æ‹…å¿ƒ", "ä¸å®‰"],
        "ç–²æƒ«": ["ç–²æƒ«", "ç´¯", "ç–²åŠ³", "å›°å€¦"],
        "çƒ¦èº": ["çƒ¦èº", "çƒ¦æ¼", "æ˜“æ€’", "æ€¥èº"],
        "å¹³é™": ["å¹³é™", "æ”¾æ¾", "å®‰é™", "å®é™"],
        "å‹åŠ›": ["å‹åŠ›", "ç´§è¿«", "è´Ÿæ‹…", "é‡å‹"]
    }
    
    for emotion, keywords in emotion_keywords.items():
        if any(keyword in user_input for keyword in keywords):
            return emotion, 0.9
    
    return "ç„¦è™‘", 0.85  # é»˜è®¤

def main():
    """ä¸»å‡½æ•° - è½»é‡çº§ç‰ˆæœ¬"""
    print("ğŸš€ å¯åŠ¨è½»é‡çº§å¢å¼ºä¸‰é˜¶æ®µç–—æ„ˆç³»ç»Ÿ...")
    print("âš¡ æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬ - å¿«é€Ÿå“åº”ï¼Œé¿å…å¡é¡¿")
    print("ğŸ¯ ä¸‰é˜¶æ®µï¼šåŒæ­¥æœŸ(30%) â†’ å¼•å¯¼æœŸ(40%) â†’ å·©å›ºæœŸ(30%)")
    print("=" * 50)
    
    # å¿«é€Ÿæµ‹è¯•åœºæ™¯
    test_scenarios = [
        "æˆ‘æ„Ÿåˆ°å¾ˆç„¦è™‘ï¼Œå¿ƒè·³åŠ é€Ÿ",
        "æˆ‘å¾ˆç–²æƒ«ï¼Œæ— æ³•æ”¾æ¾",
        "æˆ‘æ„Ÿåˆ°çƒ¦èºä¸å®‰"
    ]
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        if sys.argv[1] == "--test":
            # å¿«é€Ÿæµ‹è¯•æ¨¡å¼
            user_input = test_scenarios[0]
            duration = 5
        elif sys.argv[1] == "--demo":
            # å¤šåœºæ™¯æ¼”ç¤º
            print("ğŸ¬ è½»é‡çº§å¤šåœºæ™¯æ¼”ç¤º...")
            output_dir = Path("outputs")
            output_dir.mkdir(exist_ok=True)
            
            for i, scenario in enumerate(test_scenarios, 1):
                print(f"\nğŸ¬ åœºæ™¯ {i}: {scenario}")
                
                start_time = time.time()
                emotion, confidence = detect_emotion_simple(scenario)
                print(f"ğŸ¯ æ£€æµ‹æƒ…ç»ª: {emotion} ({confidence:.0%})")
                
                # ç”ŸæˆéŸ³é¢‘
                audio_array, sample_rate, params = generate_lightweight_therapy_audio(
                    duration=8, emotion=emotion
                )
                
                # ä¿å­˜éŸ³é¢‘
                audio_path = output_dir / f"lite_therapy_{emotion}_{i}.wav"
                success = save_audio_simple(audio_array, sample_rate, str(audio_path))
                
                processing_time = time.time() - start_time
                print(f"âœ… å®Œæˆ! å¤„ç†æ—¶é—´: {processing_time:.1f}ç§’")
                print(f"ğŸ“ ä¿å­˜è‡³: {audio_path}")
                
                if i < len(test_scenarios):
                    print("â³ å‡†å¤‡ä¸‹ä¸€ä¸ªåœºæ™¯...")
                    time.sleep(0.5)
            
            print(f"\nğŸ‰ æ‰€æœ‰åœºæ™¯å®Œæˆ! æ€»è®¡{len(test_scenarios)}ä¸ªéŸ³é¢‘æ–‡ä»¶")
            return
        else:
            user_input = " ".join(sys.argv[1:])
            duration = 10
    else:
        # é»˜è®¤åœºæ™¯
        user_input = "æˆ‘æ„Ÿåˆ°å¾ˆç„¦è™‘ï¼Œå¿ƒè·³åŠ é€Ÿï¼Œéš¾ä»¥å…¥ç¡"
        duration = 10
    
    print(f"\nğŸ’­ ç”¨æˆ·è¾“å…¥: {user_input}")
    print(f"â±ï¸ ç–—æ„ˆæ—¶é•¿: {duration}ç§’")
    print("ğŸ”„ å¼€å§‹å¤„ç†...")
    
    start_time = time.time()
    
    # æƒ…ç»ªè¯†åˆ«
    emotion, confidence = detect_emotion_simple(user_input)
    print(f"ğŸ¯ æ£€æµ‹æƒ…ç»ª: {emotion} (ç½®ä¿¡åº¦: {confidence:.0%})")
    
    # ç”ŸæˆéŸ³é¢‘
    print("ğŸµ ç”Ÿæˆè½»é‡çº§ç–—æ„ˆéŸ³é¢‘...")
    audio_array, sample_rate, params = generate_lightweight_therapy_audio(
        duration=duration, emotion=emotion
    )
    
    # ä¿å­˜éŸ³é¢‘
    output_dir = Path("outputs")
    output_dir.mkdir(exist_ok=True)
    
    timestamp = time.strftime("%H%M%S")
    audio_path = output_dir / f"lite_therapy_{emotion}_{timestamp}.wav"
    
    print("ğŸ’¾ ä¿å­˜éŸ³é¢‘æ–‡ä»¶...")
    success = save_audio_simple(audio_array, sample_rate, str(audio_path))
    
    processing_time = time.time() - start_time
    
    # è¾“å‡ºç»“æœ
    print("\n" + "=" * 50)
    print("âœ… è½»é‡çº§å¢å¼ºç–—æ„ˆéŸ³é¢‘ç”Ÿæˆå®Œæˆ!")
    print(f"""
ğŸ§  å¤„ç†ç»“æœ:
   æƒ…ç»ªç±»å‹: {emotion}
   ç½®ä¿¡åº¦: {confidence:.0%}
   å¤„ç†æ—¶é—´: {processing_time:.1f}ç§’

ğŸµ éŸ³é¢‘ä¿¡æ¯:
   æ—¶é•¿: {duration}ç§’
   é‡‡æ ·ç‡: {sample_rate}Hz
   å£°é“: ç«‹ä½“å£°
   
ğŸŒŠ ä¸‰é˜¶æ®µé¢‘ç‡:
   åŒæ­¥æœŸ: {params['sync_freq']}Hz
   å¼•å¯¼æœŸ: {params['guide_freq']}Hz  
   å·©å›ºæœŸ: {params['consolidate_freq']}Hz

ğŸ“ è¾“å‡ºæ–‡ä»¶:
   {audio_path}
   æ ¼å¼: {'WAV' if success else 'NumPyæ•°ç»„'}

ğŸ§ ä½¿ç”¨å»ºè®®:
   - ä½©æˆ´è€³æœºè†å¬
   - è·ŸéšéŸ³é¢‘èŠ‚å¥å‘¼å¸
   - æ„Ÿå—ä¸‰é˜¶æ®µè½¬æ¢
""")
    
    print("ğŸŒ™ è½»é‡çº§ç–—æ„ˆä½“éªŒå®Œæˆ!")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºé€€å‡º")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)