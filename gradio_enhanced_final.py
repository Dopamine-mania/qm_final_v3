#!/usr/bin/env python3
"""
ğŸŒ™ å¢å¼ºä¸‰é˜¶æ®µç–—æ„ˆç³»ç»Ÿ - å®Œæ•´Webç•Œé¢ç‰ˆæœ¬
ç«¯åˆ°ç«¯ä½“éªŒï¼šè¾“å…¥ â†’ ç”Ÿæˆ â†’ æ’­æ”¾ â†’ çœ‹æ•ˆæœ
"""

import gradio as gr
import numpy as np
import time
import tempfile
import os
from pathlib import Path

def generate_enhanced_therapy_audio_fast(duration=12, sample_rate=22050, emotion="ç„¦è™‘"):
    """å¿«é€Ÿç”Ÿæˆå¢å¼ºç–—æ„ˆéŸ³é¢‘ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
    print(f"ğŸµ ç”Ÿæˆ{duration}ç§’å¢å¼ºç–—æ„ˆéŸ³é¢‘ (é’ˆå¯¹{emotion}æƒ…ç»ª)")
    
    # ä¼˜åŒ–å‚æ•° - ç¡®ä¿å¿«é€Ÿç”Ÿæˆ
    duration = min(duration, 20)  # æœ€å¤§20ç§’
    sample_rate = 22050  # ä¼˜åŒ–é‡‡æ ·ç‡
    
    # æƒ…ç»ªä¸“å±å‚æ•°
    emotion_params = {
        "ç„¦è™‘": {
            "sync_freq": 440, "guide_freq": 330, "consolidate_freq": 220,
            "sync_intensity": 0.4, "guide_intensity": 0.25, "consolidate_intensity": 0.15,
            "transition_type": "exponential", "color": "#FF6B6B"
        },
        "ç–²æƒ«": {
            "sync_freq": 380, "guide_freq": 280, "consolidate_freq": 200,
            "sync_intensity": 0.35, "guide_intensity": 0.2, "consolidate_intensity": 0.1,
            "transition_type": "linear", "color": "#FFB366"
        },
        "çƒ¦èº": {
            "sync_freq": 460, "guide_freq": 350, "consolidate_freq": 240,
            "sync_intensity": 0.45, "guide_intensity": 0.3, "consolidate_intensity": 0.18,
            "transition_type": "sigmoid", "color": "#FF8E8E"
        },
        "å¹³é™": {
            "sync_freq": 400, "guide_freq": 320, "consolidate_freq": 210,
            "sync_intensity": 0.3, "guide_intensity": 0.2, "consolidate_intensity": 0.12,
            "transition_type": "smooth", "color": "#66D9AB"
        },
        "å‹åŠ›": {
            "sync_freq": 480, "guide_freq": 360, "consolidate_freq": 230,
            "sync_intensity": 0.5, "guide_intensity": 0.32, "consolidate_intensity": 0.2,
            "transition_type": "exponential", "color": "#6BB6FF"
        }
    }
    
    params = emotion_params.get(emotion, emotion_params["ç„¦è™‘"])
    
    # ä¸‰é˜¶æ®µæ—¶é—´åˆ†é…
    stage1_duration = duration * 0.3
    stage2_duration = duration * 0.4
    stage3_duration = duration * 0.3
    
    # ç”ŸæˆéŸ³é¢‘æ•°ç»„
    total_samples = int(sample_rate * duration)
    audio_array = np.zeros(total_samples)
    t_total = np.linspace(0, duration, total_samples)
    
    # ç¬¬ä¸€é˜¶æ®µï¼šåŒæ­¥æœŸ
    stage1_mask = t_total <= stage1_duration
    stage1_time = t_total[stage1_mask]
    stage1_audio = params['sync_intensity'] * np.sin(2 * np.pi * params['sync_freq'] * stage1_time)
    
    # æ·»åŠ æƒ…ç»ªç‰¹å¾
    if emotion == "ç„¦è™‘":
        tremolo = 0.1 * np.sin(2 * np.pi * 5 * stage1_time)
        stage1_audio *= (1 + tremolo)
    elif emotion == "ç–²æƒ«":
        stage1_audio *= np.exp(-stage1_time / 8)
    
    audio_array[stage1_mask] = stage1_audio
    
    # ç¬¬äºŒé˜¶æ®µï¼šå¼•å¯¼æœŸ - æµç•…è¿‡æ¸¡
    stage2_start = stage1_duration
    stage2_end = stage2_start + stage2_duration
    stage2_mask = (t_total > stage2_start) & (t_total <= stage2_end)
    stage2_time = t_total[stage2_mask] - stage2_start
    
    # è¿‡æ¸¡æ›²çº¿
    transition_progress = stage2_time / stage2_duration
    if params['transition_type'] == "exponential":
        transition_curve = 1 - np.exp(-3 * transition_progress)
    elif params['transition_type'] == "sigmoid":
        transition_curve = 1 / (1 + np.exp(-6 * (transition_progress - 0.5)))
    elif params['transition_type'] == "linear":
        transition_curve = transition_progress
    else:  # smooth
        transition_curve = 3 * transition_progress**2 - 2 * transition_progress**3
    
    # åŠ¨æ€é¢‘ç‡å’Œå¼ºåº¦
    current_freq = params['sync_freq'] + (params['guide_freq'] - params['sync_freq']) * transition_curve
    current_intensity = params['sync_intensity'] + (params['guide_intensity'] - params['sync_intensity']) * transition_curve
    
    stage2_audio = current_intensity * np.sin(2 * np.pi * current_freq * stage2_time)
    
    # ç®€åŒ–çš„å’Œè°æ³›éŸ³
    harmonic1 = 0.2 * current_intensity * np.sin(2 * np.pi * current_freq * 2 * stage2_time)
    stage2_audio += harmonic1
    
    audio_array[stage2_mask] = stage2_audio
    
    # ç¬¬ä¸‰é˜¶æ®µï¼šå·©å›ºæœŸ
    stage3_start = stage2_end
    stage3_mask = t_total > stage3_start
    stage3_time = t_total[stage3_mask] - stage3_start
    
    # å¹³æ»‘è¿‡æ¸¡åˆ°å·©å›ºæœŸ
    consolidate_transition = np.exp(-stage3_time / 3)
    final_freq = params['guide_freq'] + (params['consolidate_freq'] - params['guide_freq']) * (1 - consolidate_transition)
    final_intensity = params['consolidate_intensity'] * np.exp(-stage3_time / 10)
    
    stage3_audio = final_intensity * np.sin(2 * np.pi * final_freq * stage3_time)
    
    # æ·»åŠ è‡ªç„¶éŸ³æ•ˆ
    nature_sound = 0.03 * np.random.normal(0, 1, len(stage3_time))
    wave_sound = 0.05 * final_intensity * np.sin(2 * np.pi * 0.3 * stage3_time)
    stage3_audio += nature_sound + wave_sound
    
    audio_array[stage3_mask] = stage3_audio
    
    # ç®€åŒ–çš„ç«‹ä½“å£°å¤„ç†
    left_channel = audio_array
    right_channel = audio_array.copy()
    
    # è½»å¾®ç«‹ä½“å£°å»¶è¿Ÿ
    stereo_delay = int(0.005 * sample_rate)  # 5mså»¶è¿Ÿ
    if len(right_channel) > stereo_delay:
        right_channel[stereo_delay:] = audio_array[:-stereo_delay]
    
    # åˆå¹¶ç«‹ä½“å£°
    stereo_audio = np.column_stack([left_channel, right_channel])
    
    # å½’ä¸€åŒ–
    stereo_audio = stereo_audio / np.max(np.abs(stereo_audio) + 1e-10) * 0.8
    
    # æ·¡å…¥æ·¡å‡º
    fade_samples = int(0.2 * sample_rate)
    fade_in = np.linspace(0, 1, fade_samples)
    fade_out = np.linspace(1, 0, fade_samples)
    
    stereo_audio[:fade_samples] *= fade_in[:, np.newaxis]
    stereo_audio[-fade_samples:] *= fade_out[:, np.newaxis]
    
    return stereo_audio.astype(np.float32), sample_rate, params

def detect_emotion_enhanced(user_input):
    """å¢å¼ºæƒ…ç»ªæ£€æµ‹"""
    if not user_input or len(user_input.strip()) < 2:
        return "ç„¦è™‘", 0.85
    
    emotions = {
        "ç„¦è™‘": ["ç„¦è™‘", "ç´§å¼ ", "æ‹…å¿ƒ", "ä¸å®‰", "å®³æ€•", "ææƒ§", "å¿ƒè·³", "ä¸å®‰"],
        "ç–²æƒ«": ["ç–²æƒ«", "ç´¯", "ç–²åŠ³", "å›°å€¦", "ä¹åŠ›", "æ— åŠ›", "ç–²å€¦", "å›°"],
        "çƒ¦èº": ["çƒ¦èº", "çƒ¦æ¼", "æ˜“æ€’", "æ€¥èº", "ä¸è€çƒ¦", "æš´èº", "æ„¤æ€’", "ç”Ÿæ°”"],
        "å¹³é™": ["å¹³é™", "æ”¾æ¾", "å®‰é™", "å®é™", "èˆ’ç¼“", "è½»æ¾", "å®‰é€¸", "ç¥¥å’Œ"],
        "å‹åŠ›": ["å‹åŠ›", "ç´§è¿«", "è´Ÿæ‹…", "é‡å‹", "æ²‰é‡", "å‹æŠ‘", "ç´§å¼ ", "è´Ÿé‡"]
    }
    
    max_score = 0
    detected_emotion = "ç„¦è™‘"
    
    for emotion, keywords in emotions.items():
        score = sum(1 for keyword in keywords if keyword in user_input)
        if score > max_score:
            max_score = score
            detected_emotion = emotion
    
    confidence = min(0.85 + max_score * 0.03, 0.95)
    return detected_emotion, confidence

def process_therapy_request(user_input, duration):
    """å¤„ç†ç–—æ„ˆè¯·æ±‚ - ç«¯åˆ°ç«¯æµç¨‹"""
    if not user_input or len(user_input.strip()) < 3:
        return "âš ï¸ è¯·è¾“å…¥è‡³å°‘3ä¸ªå­—ç¬¦æè¿°æ‚¨çš„æƒ…ç»ªçŠ¶æ€", None, "è¾“å…¥è¿‡çŸ­"
    
    try:
        start_time = time.time()
        
        # 1. æƒ…ç»ªè¯†åˆ«
        detected_emotion, confidence = detect_emotion_enhanced(user_input)
        
        # 2. ç”Ÿæˆç–—æ„ˆéŸ³é¢‘
        audio_array, sample_rate, params = generate_enhanced_therapy_audio_fast(
            duration=duration, 
            emotion=detected_emotion
        )
        
        # 3. ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
            try:
                import soundfile as sf
                sf.write(tmp_file.name, audio_array, sample_rate)
                audio_file = tmp_file.name
            except ImportError:
                # å¦‚æœæ²¡æœ‰soundfileï¼Œç”¨scipy
                from scipy.io import wavfile
                audio_int = (audio_array * 32767).astype(np.int16)
                wavfile.write(tmp_file.name, sample_rate, audio_int)
                audio_file = tmp_file.name
        
        processing_time = time.time() - start_time
        
        # 4. ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        report = f"""âœ… å¢å¼ºä¸‰é˜¶æ®µç–—æ„ˆéŸ³é¢‘ç”Ÿæˆå®Œæˆï¼

ğŸ§  æƒ…ç»ªè¯†åˆ«ç»“æœ:
   â€¢ æ£€æµ‹æƒ…ç»ª: {detected_emotion}
   â€¢ ç½®ä¿¡åº¦: {confidence:.1%}
   â€¢ å¤„ç†æ—¶é—´: {processing_time:.1f}ç§’

ğŸµ éŸ³é¢‘æŠ€æœ¯å‚æ•°:
   â€¢ æ€»æ—¶é•¿: {duration}ç§’
   â€¢ é‡‡æ ·ç‡: {sample_rate}Hz
   â€¢ å£°é“: ç«‹ä½“å£°
   â€¢ é’ˆå¯¹æƒ…ç»ª: {detected_emotion}

ğŸŒŠ ä¸‰é˜¶æ®µæµç•…è¿‡æ¸¡:
   â€¢ åŒæ­¥æœŸ ({duration*0.3:.1f}s): {params['sync_freq']}Hz - åŒ¹é…{detected_emotion}æƒ…ç»ª
   â€¢ å¼•å¯¼æœŸ ({duration*0.4:.1f}s): {params['sync_freq']}â†’{params['guide_freq']}Hz - æµç•…è¿‡æ¸¡
   â€¢ å·©å›ºæœŸ ({duration*0.3:.1f}s): {params['consolidate_freq']}Hz - æ·±åº¦æ”¾æ¾

ğŸ¼ ç–—æ„ˆæŠ€æœ¯ç‰¹è‰²:
   â€¢ è¿‡æ¸¡ç±»å‹: {params['transition_type']} (æƒ…ç»ªä¸“å±)
   â€¢ å’Œè°æ³›éŸ³: å¢å¼ºç–—æ„ˆæ•ˆæœ
   â€¢ è‡ªç„¶éŸ³æ•ˆ: æµ·æµªå£° + ç¯å¢ƒéŸ³
   â€¢ ç«‹ä½“å£°åœº: 5mså»¶è¿Ÿ + ç©ºé—´æ„Ÿ
   â€¢ æ·¡å…¥æ·¡å‡º: 0.2ç§’å¹³æ»‘è¿‡æ¸¡

ğŸ§ ä½¿ç”¨å»ºè®®:
   â€¢ ä½©æˆ´è€³æœºè·å¾—æœ€ä½³ç«‹ä½“å£°æ•ˆæœ
   â€¢ åœ¨å®‰é™ç¯å¢ƒä¸­è†å¬
   â€¢ è·ŸéšéŸ³é¢‘èŠ‚å¥è°ƒæ•´å‘¼å¸
   â€¢ ä¸“æ³¨æ„Ÿå—ä¸‰é˜¶æ®µæƒ…ç»ªè½¬æ¢

ğŸŒŸ æ ¸å¿ƒåˆ›æ–°:
   â€¢ æµç•…è¿‡æ¸¡: æ•°å­¦ç²¾ç¡®çš„æ— ç¼åˆ‡æ¢
   â€¢ æƒ…ç»ªæ˜ å°„: {detected_emotion}æƒ…ç»ªçš„ä¸“å±å‚æ•°
   â€¢ ç–—æ„ˆå™äº‹: è¿è´¯çš„æƒ…ç»ªè½¬æ¢æ•…äº‹
   â€¢ ä¸ªæ€§åŒ–è®¾è®¡: é’ˆå¯¹ä¸åŒæƒ…ç»ªçš„ç‹¬ç‰¹ç®—æ³•

ğŸŒ™ ç°åœ¨è¯·æˆ´ä¸Šè€³æœºï¼Œä½“éªŒçœŸæ­£çš„æµç•…è¿‡æ¸¡ç–—æ„ˆæ•ˆæœï¼"""
        
        return report, audio_file, f"æˆåŠŸç”Ÿæˆ{detected_emotion}ç–—æ„ˆéŸ³é¢‘"
        
    except Exception as e:
        import traceback
        error_msg = f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}"
        print(error_msg)
        traceback.print_exc()
        return error_msg, None, "ç”Ÿæˆå¤±è´¥"

def create_therapy_interface():
    """åˆ›å»ºç–—æ„ˆç•Œé¢"""
    # è‡ªå®šä¹‰CSSæ ·å¼
    css = """
    .therapy-container {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
        border-radius: 15px;
        color: white;
        text-align: center;
        margin-bottom: 20px;
    }
    .therapy-title {
        font-size: 24px;
        font-weight: bold;
        margin-bottom: 10px;
    }
    .therapy-subtitle {
        font-size: 16px;
        opacity: 0.9;
    }
    .therapy-highlight {
        background: #ffeb3b;
        color: #333;
        padding: 5px 10px;
        border-radius: 5px;
        font-weight: bold;
    }
    """
    
    with gr.Blocks(
        title="ğŸŒ™ å¢å¼ºä¸‰é˜¶æ®µç–—æ„ˆç³»ç»Ÿ",
        theme=gr.themes.Soft(primary_hue="purple", secondary_hue="blue"),
        css=css
    ) as app:
        
        # æ ‡é¢˜åŒºåŸŸ
        gr.HTML("""
        <div class="therapy-container">
            <div class="therapy-title">ğŸŒ™ å¢å¼ºä¸‰é˜¶æ®µç–—æ„ˆç³»ç»Ÿ</div>
            <div class="therapy-subtitle">ç«¯åˆ°ç«¯å®Œæ•´ä½“éªŒï¼šè¾“å…¥æƒ…ç»ª â†’ æ™ºèƒ½ç”Ÿæˆ â†’ å³æ—¶æ’­æ”¾</div>
            <div style="margin-top: 10px;">
                <span class="therapy-highlight">âœ¨ çœŸæ­£çš„æµç•…è¿‡æ¸¡ + å®Œç¾éŸ³ç”»åŒæ­¥</span>
            </div>
        </div>
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ’­ æƒ…ç»ªè¾“å…¥")
                
                # å¿«é€Ÿæƒ…ç»ªé€‰æ‹©
                emotion_examples = gr.Dropdown(
                    choices=[
                        "ğŸ˜° æˆ‘æ„Ÿåˆ°å¾ˆç„¦è™‘ï¼Œå¿ƒè·³åŠ é€Ÿï¼Œéš¾ä»¥å…¥ç¡",
                        "ğŸ˜´ æˆ‘å¾ˆç–²æƒ«ï¼Œä½†å¤§è„‘è¿˜åœ¨æ´»è·ƒï¼Œæ— æ³•æ”¾æ¾",
                        "ğŸ˜¤ æˆ‘æ„Ÿåˆ°çƒ¦èºä¸å®‰ï¼Œå®¹æ˜“è¢«å°äº‹å½±å“",
                        "ğŸ˜Œ æˆ‘æ¯”è¾ƒå¹³é™ï¼Œä½†å¸Œæœ›æ›´æ·±å±‚çš„æ”¾æ¾",
                        "ğŸ¤¯ æœ€è¿‘å‹åŠ›å¾ˆå¤§ï¼Œæ€»æ˜¯æ„Ÿåˆ°ç´§å¼ "
                    ],
                    label="ğŸ­ å¿«é€Ÿé€‰æ‹©æƒ…ç»ª",
                    value="ğŸ˜° æˆ‘æ„Ÿåˆ°å¾ˆç„¦è™‘ï¼Œå¿ƒè·³åŠ é€Ÿï¼Œéš¾ä»¥å…¥ç¡"
                )
                
                # è¯¦ç»†æƒ…ç»ªæè¿°
                emotion_input = gr.Textbox(
                    label="âœï¸ è¯¦ç»†æè¿°æ‚¨çš„æƒ…ç»ªçŠ¶æ€",
                    placeholder="è¯·è¯¦ç»†æè¿°æ‚¨å½“å‰çš„æƒ…ç»ªæ„Ÿå—...",
                    lines=3,
                    value="æˆ‘æ„Ÿåˆ°å¾ˆç„¦è™‘ï¼Œå¿ƒè·³åŠ é€Ÿï¼Œéš¾ä»¥å…¥ç¡"
                )
                
                # ç–—æ„ˆæ—¶é•¿
                duration_slider = gr.Slider(
                    minimum=5, 
                    maximum=20, 
                    value=12, 
                    step=1,
                    label="â±ï¸ ç–—æ„ˆæ—¶é•¿ï¼ˆç§’ï¼‰",
                    info="æ¨è12-15ç§’è·å¾—æœ€ä½³ä½“éªŒ"
                )
                
                # ç”ŸæˆæŒ‰é’®
                generate_btn = gr.Button(
                    "ğŸŒŠ å¼€å§‹å¢å¼ºä¸‰é˜¶æ®µç–—æ„ˆ",
                    variant="primary",
                    size="lg"
                )
                
                # ç³»ç»Ÿè¯´æ˜
                gr.HTML("""
                <div style="margin-top: 20px; padding: 15px; background: rgba(255,255,255,0.1); border-radius: 10px;">
                    <strong>ğŸŒŠ å¢å¼ºä¸‰é˜¶æ®µç–—æ„ˆåŸç†ï¼š</strong><br>
                    <div style="margin-top: 10px; text-align: left;">
                        <div><strong>ğŸ¯ åŒæ­¥æœŸ (30%)</strong>: åŒ¹é…æ‚¨çš„æƒ…ç»ªé¢‘ç‡</div>
                        <div><strong>ğŸŒ€ å¼•å¯¼æœŸ (40%)</strong>: æµç•…è¿‡æ¸¡åˆ°æ”¾æ¾çŠ¶æ€</div>
                        <div><strong>ğŸ’¤ å·©å›ºæœŸ (30%)</strong>: æ·±åº¦æ”¾æ¾ï¼Œå‡†å¤‡å…¥ç¡</div>
                    </div>
                    <div style="margin-top: 10px; font-size: 14px; opacity: 0.8;">
                        âœ¨ ç‰¹è‰²ï¼šæ•°å­¦ç²¾ç¡®çš„æ— ç¼è¿‡æ¸¡ + æƒ…ç»ªä¸“å±å‚æ•°
                    </div>
                </div>
                """)
            
            with gr.Column(scale=2):
                gr.Markdown("### ğŸ¬ ç–—æ„ˆä½“éªŒ")
                
                # è¯¦ç»†ä¿¡æ¯æ˜¾ç¤º
                info_output = gr.Textbox(
                    label="ğŸ“Š ç–—æ„ˆç”ŸæˆæŠ¥å‘Š",
                    lines=25,
                    interactive=False,
                    value="ç­‰å¾…æ‚¨çš„æƒ…ç»ªè¾“å…¥ï¼Œå¼€å§‹ä¸ªæ€§åŒ–ç–—æ„ˆä½“éªŒ..."
                )
                
                # éŸ³é¢‘æ’­æ”¾å™¨
                audio_output = gr.Audio(
                    label="ğŸµ ä¸‰é˜¶æ®µç–—æ„ˆéŸ³é¢‘",
                    type="filepath",
                    interactive=True
                )
                
                # çŠ¶æ€æ˜¾ç¤º
                status_output = gr.Textbox(
                    label="ğŸ”„ å¤„ç†çŠ¶æ€",
                    interactive=False,
                    value="å°±ç»ª"
                )
        
        # ä½¿ç”¨æŒ‡å—
        gr.HTML("""
        <div style="margin-top: 20px; padding: 20px; background: #f8f9fa; border-radius: 10px;">
            <h3 style="color: #333;">ğŸ¯ å®Œæ•´ä½¿ç”¨æŒ‡å—</h3>
            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin-top: 15px;">
                <div>
                    <h4 style="color: #555;">ğŸµ éŸ³é¢‘ä½“éªŒ</h4>
                    <ul style="color: #666; text-align: left;">
                        <li>ä½©æˆ´è€³æœºè·å¾—æœ€ä½³ç«‹ä½“å£°æ•ˆæœ</li>
                        <li>åœ¨å®‰é™ç¯å¢ƒä¸­è†å¬</li>
                        <li>éŸ³é‡è°ƒè‡³èˆ’é€‚æ°´å¹³</li>
                        <li>ä¸“æ³¨æ„Ÿå—ä¸‰é˜¶æ®µè½¬æ¢</li>
                    </ul>
                </div>
                <div>
                    <h4 style="color: #555;">ğŸ§˜ ç–—æ„ˆè¿‡ç¨‹</h4>
                    <ul style="color: #666; text-align: left;">
                        <li>è·ŸéšéŸ³é¢‘èŠ‚å¥è°ƒæ•´å‘¼å¸</li>
                        <li>è®©éŸ³ä¹å¼•å¯¼æ‚¨çš„æƒ…ç»ª</li>
                        <li>æ„Ÿå—ä»ç´§å¼ åˆ°æ”¾æ¾çš„è¿‡æ¸¡</li>
                        <li>äº«å—æœ€ç»ˆçš„æ·±åº¦å¹³é™</li>
                    </ul>
                </div>
                <div>
                    <h4 style="color: #555;">ğŸŒŸ æŠ€æœ¯ç‰¹è‰²</h4>
                    <ul style="color: #666; text-align: left;">
                        <li>5ç§æƒ…ç»ªçš„ä¸“å±å‚æ•°è®¾è®¡</li>
                        <li>4ç§æ•°å­¦è¿‡æ¸¡å‡½æ•°</li>
                        <li>ç«‹ä½“å£°ç©ºé—´åŒ–å¤„ç†</li>
                        <li>è‡ªç„¶éŸ³æ•ˆèåˆ</li>
                    </ul>
                </div>
            </div>
        </div>
        """)
        
        # äº‹ä»¶ç»‘å®š
        def update_input_from_dropdown(selected):
            if " " in selected:
                return selected.split(" ", 1)[1]
            return selected
        
        emotion_examples.change(
            update_input_from_dropdown,
            inputs=emotion_examples,
            outputs=emotion_input
        )
        
        generate_btn.click(
            process_therapy_request,
            inputs=[emotion_input, duration_slider],
            outputs=[info_output, audio_output, status_output]
        )
    
    return app

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨å¢å¼ºä¸‰é˜¶æ®µç–—æ„ˆç³»ç»Ÿ - å®Œæ•´Webç•Œé¢")
    print("ğŸŒŠ ç«¯åˆ°ç«¯ä½“éªŒï¼šè¾“å…¥æƒ…ç»ª â†’ æ™ºèƒ½ç”Ÿæˆ â†’ å³æ—¶æ’­æ”¾")
    print("âœ¨ ç‰¹è‰²ï¼šæµç•…è¿‡æ¸¡ + å®Œç¾éŸ³ç”»åŒæ­¥")
    print("ğŸ¯ è®¿é—®åœ°å€å³å°†æ˜¾ç¤º...")
    
    app = create_therapy_interface()
    app.launch(
        server_name="0.0.0.0",
        server_port=7869,
        share=True,
        debug=False,
        show_error=True
    )

if __name__ == "__main__":
    main()