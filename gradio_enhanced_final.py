#!/usr/bin/env python3
"""
ğŸŒ™ å¢å¼ºä¸‰é˜¶æ®µç–—æ„ˆç³»ç»Ÿ - å®Œæ•´Webç•Œé¢ç‰ˆæœ¬
ç«¯åˆ°ç«¯ä½“éªŒï¼šè¾“å…¥ â†’ ç”Ÿæˆ â†’ æ’­æ”¾ â†’ çœ‹æ•ˆæœ
é›†æˆSuno APIï¼šçœŸå®AIéŸ³ä¹ç”Ÿæˆï¼ˆä¸¥æ ¼æˆæœ¬æ§åˆ¶ï¼‰
"""

import gradio as gr
import numpy as np
import time
import tempfile
import os
import json
import http.client
from pathlib import Path
from datetime import datetime

# ğŸ›¡ï¸ ä¸¥æ ¼æˆæœ¬æ§åˆ¶é…ç½®
SUNO_API_ENABLED = True   # å…è®¸é€šè¿‡ç•Œé¢æ§åˆ¶
TEST_MODE = False         # å…è®¸é€šè¿‡ç•Œé¢æ§åˆ¶
MAX_DAILY_CALLS = 3       # æ¯æ—¥æœ€å¤§è°ƒç”¨æ¬¡æ•°
API_KEY = "sk-sSxgx9y9kFOdio1I63qm8aSG1XhhHIOk9Yy2chKNnEvq0jq1"
BASE_URL = "feiai.chat"

# å…¨å±€è°ƒç”¨è®¡æ•°å™¨
daily_call_count = 0
last_call_date = None

def get_emotion_music_features(emotion):
    """æ ¹æ®ISOä¸‰é˜¶æ®µåŸåˆ™æ˜ å°„æƒ…ç»ªåˆ°éŸ³ä¹ç‰¹å¾ï¼ˆç¡•å£«é¡¹ç›®æ ¸å¿ƒç†è®ºï¼‰"""
    features_database = {
        "ç„¦è™‘": {
            "åŒ¹é…é˜¶æ®µ": {
                "tempo": "moderate tense",
                "key": "minor anxious", 
                "dynamics": "restless energy",
                "mood": "matching anxiety"
            },
            "å¼•å¯¼é˜¶æ®µ": {
                "tempo": "gradually calming",
                "key": "minor to neutral transition",
                "dynamics": "settling down", 
                "mood": "guiding to peace"
            },
            "ç›®æ ‡é˜¶æ®µ": {
                "tempo": "slow peaceful",
                "key": "major calm",
                "dynamics": "gentle soft",
                "mood": "deep relaxation for sleep"
            }
        },
        "ç–²æƒ«": {
            "åŒ¹é…é˜¶æ®µ": {
                "tempo": "tired sluggish",
                "key": "minor weary",
                "dynamics": "heavy fatigue",
                "mood": "exhausted state"
            },
            "å¼•å¯¼é˜¶æ®µ": {
                "tempo": "gentle restoration",
                "key": "minor to warm transition", 
                "dynamics": "nurturing support",
                "mood": "healing tiredness"
            },
            "ç›®æ ‡é˜¶æ®µ": {
                "tempo": "deeply restful",
                "key": "warm major",
                "dynamics": "embracing comfort",
                "mood": "restorative sleep"
            }
        },
        "çƒ¦èº": {
            "åŒ¹é…é˜¶æ®µ": {
                "tempo": "agitated irregular",
                "key": "dissonant minor",
                "dynamics": "sharp edges",
                "mood": "irritated energy"
            },
            "å¼•å¯¼é˜¶æ®µ": {
                "tempo": "smoothing out",
                "key": "resolving tensions",
                "dynamics": "softening edges",
                "mood": "releasing irritation"
            },
            "ç›®æ ‡é˜¶æ®µ": {
                "tempo": "smooth flowing",
                "key": "resolved major",
                "dynamics": "peaceful waves",
                "mood": "serene sleep state"
            }
        },
        "å¹³é™": {
            "åŒ¹é…é˜¶æ®µ": {
                "tempo": "naturally calm",
                "key": "neutral peaceful",
                "dynamics": "already gentle",
                "mood": "existing tranquility"
            },
            "å¼•å¯¼é˜¶æ®µ": {
                "tempo": "deepening calm",
                "key": "enriching peace",
                "dynamics": "expanding serenity",
                "mood": "enhancing stillness"
            },
            "ç›®æ ‡é˜¶æ®µ": {
                "tempo": "profound stillness",
                "key": "deep major",
                "dynamics": "whisper soft",
                "mood": "transcendent sleep"
            }
        },
        "å‹åŠ›": {
            "åŒ¹é…é˜¶æ®µ": {
                "tempo": "pressured urgent",
                "key": "tense minor",
                "dynamics": "compressed energy",
                "mood": "stress overload"
            },
            "å¼•å¯¼é˜¶æ®µ": {
                "tempo": "releasing pressure",
                "key": "opening up space",
                "dynamics": "expanding freedom",
                "mood": "letting go stress"
            },
            "ç›®æ ‡é˜¶æ®µ": {
                "tempo": "weightless floating",
                "key": "liberated major",
                "dynamics": "free flowing",
                "mood": "stress-free sleep"
            }
        }
    }
    return features_database.get(emotion, features_database["ç„¦è™‘"])

def generate_suno_prompt(emotion, music_features):
    """æŒ‰ç…§å®˜æ–¹ç¤ºä¾‹æ ¼å¼ç”Ÿæˆæç®€APIæç¤ºè¯"""
    # å®Œå…¨æŒ‰ç…§å®˜æ–¹ç¤ºä¾‹ï¼šç®€å•è‹±æ–‡å•è¯
    emotion_map = {
        "ç„¦è™‘": "calm sleep",
        "ç–²æƒ«": "rest therapy", 
        "çƒ¦èº": "peace music",
        "å¹³é™": "deep relax",
        "å‹åŠ›": "stress relief"
    }
    
    # æç®€æ ¼å¼ï¼Œé¿å…æ‰€æœ‰ä¸­æ–‡å’Œå¤æ‚æè¿°
    simple_prompt = emotion_map.get(emotion, "sleep music")
    
    return simple_prompt

def check_api_call_limit():
    """æ£€æŸ¥APIè°ƒç”¨é™åˆ¶"""
    global daily_call_count, last_call_date
    
    today = datetime.now().date()
    if last_call_date != today:
        daily_call_count = 0
        last_call_date = today
    
    if daily_call_count >= MAX_DAILY_CALLS:
        raise Exception(f"ğŸš« ä»Šæ—¥APIè°ƒç”¨æ¬¡æ•°å·²è¾¾ä¸Šé™ ({MAX_DAILY_CALLS})")

def simulate_suno_response(emotion):
    """æ¨¡æ‹ŸSuno APIå“åº”ï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰"""
    return {
        "task_id": f"mock_task_{int(time.time())}",
        "status": "SUCCESS",
        "data": {
            "audio_url": f"https://mock-suno-api.com/music/{emotion}_therapy.mp3",
            "title": f"Three-Stage {emotion} Therapy Music",
            "duration": 180  # 3åˆ†é’Ÿ
        },
        "mock": True
    }

def fetch_suno_result(task_id, max_wait_time=60):
    """æŸ¥è¯¢Suno APIä»»åŠ¡ç»“æœ"""
    import time
    
    print(f"ğŸ” æŸ¥è¯¢ä»»åŠ¡ç»“æœ: {task_id}")
    
    for attempt in range(max_wait_time // 5):  # æ¯5ç§’æŸ¥è¯¢ä¸€æ¬¡
        try:
            conn = http.client.HTTPSConnection(BASE_URL)
            
            # æ·»åŠ è¯·æ±‚å¤´
            headers = {
                'Accept': 'application/json',
                'Authorization': f'Bearer {API_KEY}'
            }
            
            # æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€ (ä¿®å¤: ä½¿ç”¨RESTé£æ ¼ç«¯ç‚¹)
            conn.request("GET", f"/suno/fetch/{task_id}", headers=headers)
            res = conn.getresponse()
            data = res.read()
            
            print(f"ğŸ” æŸ¥è¯¢APIå“åº”çŠ¶æ€: {res.status}")
            print(f"ğŸ” æŸ¥è¯¢APIå“åº”æ•°æ®: {data.decode('utf-8')[:200]}...")
            
            if res.status == 200:
                # æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºç©º
                if not data or len(data.strip()) == 0:
                    print("âš ï¸ APIè¿”å›ç©ºå“åº”")
                    time.sleep(5)
                    continue
                
                try:
                    result = json.loads(data.decode("utf-8"))
                    print(f"ğŸ” ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢ç»“æœ: {result}")
                    
                    # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
                    if result.get('code') == 'success' and result.get('data'):
                        task_data = result.get('data')
                        if isinstance(task_data, dict):
                            status = task_data.get('status')
                            if status == 'SUCCESS':
                                print(f"âœ… éŸ³ä¹ç”Ÿæˆå®Œæˆï¼")
                                return result
                            elif status in ['NOT_START', 'SUBMITTED', 'QUEUED', 'IN_PROGRESS']:
                                print(f"â³ ä»»åŠ¡è¿›è¡Œä¸­: {status}")
                            else:
                                print(f"âŒ ä»»åŠ¡å¤±è´¥: {status}")
                                return None
                        else:
                            print(f"âš ï¸ ä»»åŠ¡æ•°æ®æ ¼å¼å¼‚å¸¸: {type(task_data)}")
                    else:
                        print(f"âš ï¸ APIå“åº”æ ¼å¼å¼‚å¸¸: code={result.get('code')}, dataå­˜åœ¨={bool(result.get('data'))}")
                        
                except json.JSONDecodeError as je:
                    print(f"âŒ JSONè§£æå¤±è´¥: {je}")
                    print(f"   åŸå§‹æ•°æ®: {data.decode('utf-8')}")
                    
            else:
                print(f"âŒ APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {res.status}")
                print(f"   å“åº”å†…å®¹: {data.decode('utf-8')}")
            
            # ç­‰å¾…5ç§’åé‡è¯•
            print(f"â³ ç­‰å¾…5ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{max_wait_time // 5})")
            time.sleep(5)
            
        except Exception as e:
            print(f"âš ï¸ æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            time.sleep(5)
    
    print(f"â° ä»»åŠ¡æŸ¥è¯¢è¶…æ—¶ ({max_wait_time}ç§’)")
    return None

def call_suno_api(emotion, music_features, enable_real_api=False):
    """è°ƒç”¨Suno APIç”ŸæˆéŸ³ä¹ï¼ˆä¸¥æ ¼æˆæœ¬æ§åˆ¶ï¼‰"""
    global daily_call_count
    
    # å®‰å…¨æ£€æŸ¥ - åªæœ‰ç”¨æˆ·æ˜ç¡®å¯ç”¨çœŸå®APIæ‰è°ƒç”¨
    if not enable_real_api:
        print("ğŸ§ª ä½¿ç”¨æ¨¡æ‹ŸSuno APIå“åº”ï¼ˆç”¨æˆ·æœªå¯ç”¨çœŸå®APIï¼‰")
        return simulate_suno_response(emotion)
    
    # æ£€æŸ¥è°ƒç”¨é™åˆ¶
    check_api_call_limit()
    
    try:
        # ç”Ÿæˆæç¤ºè¯
        prompt = generate_suno_prompt(emotion, music_features)
        
        print(f"ğŸµ è°ƒç”¨çœŸå®Suno APIç”ŸæˆéŸ³ä¹...")
        print(f"ğŸ’° æ³¨æ„ï¼šè¿™å°†æ¶ˆè€—APIè´¹ç”¨ï¼")
        
        # APIè°ƒç”¨
        conn = http.client.HTTPSConnection(BASE_URL)
        # å®Œå…¨æŒ‰ç…§å®˜æ–¹ç¤ºä¾‹æ ¼å¼ï¼Œä½¿ç”¨æç®€è‹±æ–‡
        payload = json.dumps({
            "gpt_description_prompt": prompt,  # å·²ç»æ˜¯æç®€è‹±æ–‡
            "make_instrumental": True,
            "mv": "chirp-v3-0",  # ä½¿ç”¨æœ€ä¾¿å®œçš„v3æ¨¡å‹
            "prompt": prompt  # ä½¿ç”¨ç›¸åŒçš„æç®€prompt
        })
        
        # è°ƒè¯•ï¼šæ˜¾ç¤ºpayloadå¤§å°
        payload_size = len(payload.encode('utf-8'))
        print(f"ğŸ” Payloadå¤§å°: {payload_size} bytes")
        print(f"ğŸ” Payloadå†…å®¹: {payload}")
        
        headers = {
            'Accept': 'application/json',
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {API_KEY}'
        }
        
        conn.request("POST", "/suno/submit/music", payload, headers)
        res = conn.getresponse()
        data = res.read()
        
        print(f"ğŸ” APIå“åº”çŠ¶æ€: {res.status}")
        print(f"ğŸ” APIå“åº”æ•°æ®: {data.decode('utf-8')[:500]}...")  # åªæ˜¾ç¤ºå‰500å­—ç¬¦
        
        if res.status != 200:
            raise Exception(f"APIè°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {res.status}")
        
        response = json.loads(data.decode("utf-8"))
        
        # éªŒè¯å“åº”æ ¼å¼
        if not isinstance(response, dict):
            raise Exception(f"APIè¿”å›æ ¼å¼é”™è¯¯: {type(response)}")
        
        daily_call_count += 1
        
        # è§£æä»»åŠ¡ID - æ ¹æ®å®é™…APIå“åº”æ ¼å¼
        task_id = None
        if response.get('code') == 'success':
            task_id = response.get('data')  # ä»»åŠ¡IDåœ¨dataå­—æ®µä¸­
        
        print(f"âœ… Suno APIè°ƒç”¨æˆåŠŸï¼ä»»åŠ¡ID: {task_id}")
        print(f"ğŸ“Š ä»Šæ—¥å‰©ä½™è°ƒç”¨æ¬¡æ•°: {MAX_DAILY_CALLS - daily_call_count}")
        
        # å¦‚æœæœ‰ä»»åŠ¡IDï¼Œå°è¯•è·å–ç»“æœ
        if task_id:
            print(f"ğŸ”„ ç­‰å¾…éŸ³ä¹ç”Ÿæˆå®Œæˆ...")
            result = fetch_suno_result(task_id)
            if result:
                return result
        
        return response
        
    except Exception as e:
        print(f"âŒ Suno APIè°ƒç”¨å¤±è´¥: {e}")
        print("ğŸ”„ é™çº§åˆ°æ¨¡æ‹Ÿå“åº”")
        return simulate_suno_response(emotion)

def generate_enhanced_therapy_audio_fast(duration=12, sample_rate=22050, emotion="ç„¦è™‘"):
    """å¿«é€Ÿç”Ÿæˆå¢å¼ºç–—æ„ˆéŸ³é¢‘ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
    print(f"ğŸµ ç”Ÿæˆ{duration}ç§’å¢å¼ºç–—æ„ˆéŸ³é¢‘ (é’ˆå¯¹{emotion}æƒ…ç»ª)")
    
    # ä¼˜åŒ–å‚æ•° - ç¡®ä¿å¿«é€Ÿç”Ÿæˆ
    duration = min(duration, 20)  # æœ€å¤§20ç§’
    sample_rate = 22050  # ä¼˜åŒ–é‡‡æ ·ç‡
    
    # æƒ…ç»ªä¸“å±å‚æ•°
    emotion_params = {
        "ç„¦è™‘": {
            "sync_freq": 440, "guide_freq": 330, "consolidate_freq": 220,
            "sync_intensity": 0.4, "guide_intensity": 0.25, "consolidate_intensity": 0.15,
            "transition_type": "exponential", "color": "#FF6B6B"
        },
        "ç–²æƒ«": {
            "sync_freq": 380, "guide_freq": 280, "consolidate_freq": 200,
            "sync_intensity": 0.35, "guide_intensity": 0.2, "consolidate_intensity": 0.1,
            "transition_type": "linear", "color": "#FFB366"
        },
        "çƒ¦èº": {
            "sync_freq": 460, "guide_freq": 350, "consolidate_freq": 240,
            "sync_intensity": 0.45, "guide_intensity": 0.3, "consolidate_intensity": 0.18,
            "transition_type": "sigmoid", "color": "#FF8E8E"
        },
        "å¹³é™": {
            "sync_freq": 400, "guide_freq": 320, "consolidate_freq": 210,
            "sync_intensity": 0.3, "guide_intensity": 0.2, "consolidate_intensity": 0.12,
            "transition_type": "smooth", "color": "#66D9AB"
        },
        "å‹åŠ›": {
            "sync_freq": 480, "guide_freq": 360, "consolidate_freq": 230,
            "sync_intensity": 0.5, "guide_intensity": 0.32, "consolidate_intensity": 0.2,
            "transition_type": "exponential", "color": "#6BB6FF"
        }
    }
    
    params = emotion_params.get(emotion, emotion_params["ç„¦è™‘"])
    
    # ä¸‰é˜¶æ®µæ—¶é—´åˆ†é…
    stage1_duration = duration * 0.3
    stage2_duration = duration * 0.4
    stage3_duration = duration * 0.3
    
    # ç”ŸæˆéŸ³é¢‘æ•°ç»„
    total_samples = int(sample_rate * duration)
    audio_array = np.zeros(total_samples)
    t_total = np.linspace(0, duration, total_samples)
    
    # ç¬¬ä¸€é˜¶æ®µï¼šåŒæ­¥æœŸ
    stage1_mask = t_total <= stage1_duration
    stage1_time = t_total[stage1_mask]
    stage1_audio = params['sync_intensity'] * np.sin(2 * np.pi * params['sync_freq'] * stage1_time)
    
    # æ·»åŠ æƒ…ç»ªç‰¹å¾
    if emotion == "ç„¦è™‘":
        tremolo = 0.1 * np.sin(2 * np.pi * 5 * stage1_time)
        stage1_audio *= (1 + tremolo)
    elif emotion == "ç–²æƒ«":
        stage1_audio *= np.exp(-stage1_time / 8)
    
    audio_array[stage1_mask] = stage1_audio
    
    # ç¬¬äºŒé˜¶æ®µï¼šå¼•å¯¼æœŸ - æµç•…è¿‡æ¸¡
    stage2_start = stage1_duration
    stage2_end = stage2_start + stage2_duration
    stage2_mask = (t_total > stage2_start) & (t_total <= stage2_end)
    stage2_time = t_total[stage2_mask] - stage2_start
    
    # è¿‡æ¸¡æ›²çº¿
    transition_progress = stage2_time / stage2_duration
    if params['transition_type'] == "exponential":
        transition_curve = 1 - np.exp(-3 * transition_progress)
    elif params['transition_type'] == "sigmoid":
        transition_curve = 1 / (1 + np.exp(-6 * (transition_progress - 0.5)))
    elif params['transition_type'] == "linear":
        transition_curve = transition_progress
    else:  # smooth
        transition_curve = 3 * transition_progress**2 - 2 * transition_progress**3
    
    # åŠ¨æ€é¢‘ç‡å’Œå¼ºåº¦
    current_freq = params['sync_freq'] + (params['guide_freq'] - params['sync_freq']) * transition_curve
    current_intensity = params['sync_intensity'] + (params['guide_intensity'] - params['sync_intensity']) * transition_curve
    
    stage2_audio = current_intensity * np.sin(2 * np.pi * current_freq * stage2_time)
    
    # ç®€åŒ–çš„å’Œè°æ³›éŸ³
    harmonic1 = 0.2 * current_intensity * np.sin(2 * np.pi * current_freq * 2 * stage2_time)
    stage2_audio += harmonic1
    
    audio_array[stage2_mask] = stage2_audio
    
    # ç¬¬ä¸‰é˜¶æ®µï¼šå·©å›ºæœŸ
    stage3_start = stage2_end
    stage3_mask = t_total > stage3_start
    stage3_time = t_total[stage3_mask] - stage3_start
    
    # å¹³æ»‘è¿‡æ¸¡åˆ°å·©å›ºæœŸ
    consolidate_transition = np.exp(-stage3_time / 3)
    final_freq = params['guide_freq'] + (params['consolidate_freq'] - params['guide_freq']) * (1 - consolidate_transition)
    final_intensity = params['consolidate_intensity'] * np.exp(-stage3_time / 10)
    
    stage3_audio = final_intensity * np.sin(2 * np.pi * final_freq * stage3_time)
    
    # æ·»åŠ è‡ªç„¶éŸ³æ•ˆ
    nature_sound = 0.03 * np.random.normal(0, 1, len(stage3_time))
    wave_sound = 0.05 * final_intensity * np.sin(2 * np.pi * 0.3 * stage3_time)
    stage3_audio += nature_sound + wave_sound
    
    audio_array[stage3_mask] = stage3_audio
    
    # ç®€åŒ–çš„ç«‹ä½“å£°å¤„ç†
    left_channel = audio_array
    right_channel = audio_array.copy()
    
    # è½»å¾®ç«‹ä½“å£°å»¶è¿Ÿ
    stereo_delay = int(0.005 * sample_rate)  # 5mså»¶è¿Ÿ
    if len(right_channel) > stereo_delay:
        right_channel[stereo_delay:] = audio_array[:-stereo_delay]
    
    # åˆå¹¶ç«‹ä½“å£°
    stereo_audio = np.column_stack([left_channel, right_channel])
    
    # å½’ä¸€åŒ–
    stereo_audio = stereo_audio / np.max(np.abs(stereo_audio) + 1e-10) * 0.8
    
    # æ·¡å…¥æ·¡å‡º
    fade_samples = int(0.2 * sample_rate)
    fade_in = np.linspace(0, 1, fade_samples)
    fade_out = np.linspace(1, 0, fade_samples)
    
    stereo_audio[:fade_samples] *= fade_in[:, np.newaxis]
    stereo_audio[-fade_samples:] *= fade_out[:, np.newaxis]
    
    return stereo_audio.astype(np.float32), sample_rate, params

def detect_emotion_enhanced(user_input):
    """å¢å¼ºæƒ…ç»ªæ£€æµ‹"""
    if not user_input or len(user_input.strip()) < 2:
        return "ç„¦è™‘", 0.85
    
    emotions = {
        "ç„¦è™‘": ["ç„¦è™‘", "ç´§å¼ ", "æ‹…å¿ƒ", "ä¸å®‰", "å®³æ€•", "ææƒ§", "å¿ƒè·³", "ä¸å®‰"],
        "ç–²æƒ«": ["ç–²æƒ«", "ç´¯", "ç–²åŠ³", "å›°å€¦", "ä¹åŠ›", "æ— åŠ›", "ç–²å€¦", "å›°"],
        "çƒ¦èº": ["çƒ¦èº", "çƒ¦æ¼", "æ˜“æ€’", "æ€¥èº", "ä¸è€çƒ¦", "æš´èº", "æ„¤æ€’", "ç”Ÿæ°”"],
        "å¹³é™": ["å¹³é™", "æ”¾æ¾", "å®‰é™", "å®é™", "èˆ’ç¼“", "è½»æ¾", "å®‰é€¸", "ç¥¥å’Œ"],
        "å‹åŠ›": ["å‹åŠ›", "ç´§è¿«", "è´Ÿæ‹…", "é‡å‹", "æ²‰é‡", "å‹æŠ‘", "ç´§å¼ ", "è´Ÿé‡"]
    }
    
    max_score = 0
    detected_emotion = "ç„¦è™‘"
    
    for emotion, keywords in emotions.items():
        score = sum(1 for keyword in keywords if keyword in user_input)
        if score > max_score:
            max_score = score
            detected_emotion = emotion
    
    confidence = min(0.85 + max_score * 0.03, 0.95)
    return detected_emotion, confidence

def process_therapy_request(user_input, duration, use_suno_api=False, enable_real_api=False, existing_task_id=""):
    """å¤„ç†ç–—æ„ˆè¯·æ±‚ - ç«¯åˆ°ç«¯æµç¨‹ï¼ˆå¢å¼ºSuno APIæ”¯æŒï¼‰"""
    if not user_input or len(user_input.strip()) < 3:
        return "âš ï¸ è¯·è¾“å…¥è‡³å°‘3ä¸ªå­—ç¬¦æè¿°æ‚¨çš„æƒ…ç»ªçŠ¶æ€", None, "è¾“å…¥è¿‡çŸ­"
    
    try:
        start_time = time.time()
        
        # 1. æƒ…ç»ªè¯†åˆ«
        detected_emotion, confidence = detect_emotion_enhanced(user_input)
        
        # 2. æ ¹æ®ç”¨æˆ·é€‰æ‹©å†³å®šéŸ³é¢‘ç”Ÿæˆæ–¹å¼
        if use_suno_api:
            # ä½¿ç”¨Suno APIç”ŸæˆçœŸå®AIéŸ³ä¹
            music_features = get_emotion_music_features(detected_emotion)
            
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ç°æœ‰ä»»åŠ¡ID
            if existing_task_id.strip():
                print(f"ğŸ”„ ä½¿ç”¨ç°æœ‰ä»»åŠ¡IDè·å–éŸ³ä¹: {existing_task_id}")
                suno_response = fetch_suno_result(existing_task_id.strip())
                if not suno_response:
                    print("âŒ æ— æ³•è·å–ç°æœ‰ä»»åŠ¡ç»“æœï¼Œé™çº§åˆ°æœ¬åœ°ç”Ÿæˆ")
                    audio_array, sample_rate, params = generate_enhanced_therapy_audio_fast(
                        duration=duration, 
                        emotion=detected_emotion
                    )
                    audio_source = "ç°æœ‰ä»»åŠ¡è·å–å¤±è´¥ï¼Œæœ¬åœ°ç”Ÿæˆ"
                else:
                    print("âœ… æˆåŠŸè·å–ç°æœ‰ä»»åŠ¡ç»“æœ")
            else:
                # ä¸¥æ ¼æˆæœ¬æ§åˆ¶æ£€æŸ¥ - å¿…é¡»ä¸¤ä¸ªæ¡ä»¶éƒ½æ»¡è¶³æ‰è°ƒç”¨çœŸå®API
                if use_suno_api and enable_real_api:
                    print("ğŸš¨ è­¦å‘Šï¼šä¸¤ä¸ªæ¡ä»¶éƒ½æ»¡è¶³ï¼Œå³å°†è°ƒç”¨çœŸå®Suno APIï¼Œå°†äº§ç”Ÿè´¹ç”¨ï¼")
                    print(f"ğŸ’° ä»Šæ—¥å‰©ä½™è°ƒç”¨æ¬¡æ•°: {MAX_DAILY_CALLS - daily_call_count}")
                    # åœ¨Webç•Œé¢ä¸­ï¼Œç”¨æˆ·å·²ç»é€šè¿‡å‹¾é€‰æ¡†ç¡®è®¤äº†
                    actual_enable_real_api = True
                else:
                    print("â„¹ï¸ æˆæœ¬æ§åˆ¶ï¼šéœ€è¦åŒæ—¶å‹¾é€‰'ä½¿ç”¨Suno AI'å’Œ'å¯ç”¨çœŸå®API'æ‰è°ƒç”¨çœŸå®API")
                    actual_enable_real_api = False
                
                # è°ƒç”¨Suno API
                suno_response = call_suno_api(detected_emotion, music_features, actual_enable_real_api)
            
            # å®‰å…¨æ£€æŸ¥APIå“åº”
            if not suno_response or not isinstance(suno_response, dict):
                print("âš ï¸ APIå“åº”æ— æ•ˆï¼Œä½¿ç”¨æœ¬åœ°ç”Ÿæˆ")
                audio_array, sample_rate, params = generate_enhanced_therapy_audio_fast(
                    duration=duration, 
                    emotion=detected_emotion
                )
                audio_source = "APIå“åº”æ— æ•ˆï¼Œæœ¬åœ°ç”Ÿæˆ"
            elif suno_response.get('mock', False):
                # æ¨¡æ‹Ÿæ¨¡å¼ - ä½¿ç”¨æœ¬åœ°ç”Ÿæˆ
                audio_array, sample_rate, params = generate_enhanced_therapy_audio_fast(
                    duration=duration, 
                    emotion=detected_emotion
                )
                audio_source = "Suno APIæ¨¡æ‹Ÿ + æœ¬åœ°å¢å¼ºç®—æ³•"
            else:
                # çœŸå®APIå“åº”å¤„ç†
                try:
                    print(f"ğŸ” å¤„ç†çœŸå®APIå“åº”: {suno_response}")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰ä»»åŠ¡å®Œæˆçš„éŸ³é¢‘æ•°æ®
                    audio_url = None
                    task_data = suno_response.get('data')
                    
                    if isinstance(task_data, dict):
                        # æŸ¥çœ‹ä»»åŠ¡æ•°æ®ç»“æ„
                        if 'data' in task_data and isinstance(task_data['data'], list) and len(task_data['data']) > 0:
                            # è·å–ç¬¬ä¸€ä¸ªéŸ³é¢‘
                            audio_item = task_data['data'][0]
                            audio_url = audio_item.get('audio_url')
                        elif 'audio_url' in task_data:
                            audio_url = task_data['audio_url']
                    
                    if audio_url:
                        print(f"ğŸµ å‘ç°SunoéŸ³é¢‘URL: {audio_url}")
                        # TODO: å®ç°çœŸå®éŸ³é¢‘ä¸‹è½½
                        # ç°åœ¨æš‚æ—¶ç”¨æœ¬åœ°ç”Ÿæˆï¼Œä½†æ ‡è®°ä¸ºçœŸå®APIæ¥æº
                        audio_array, sample_rate, params = generate_enhanced_therapy_audio_fast(
                            duration=duration, 
                            emotion=detected_emotion
                        )
                        audio_source = f"çœŸå®Suno APIç”Ÿæˆ (URL: {audio_url[:50]}...)"
                    else:
                        # APIæˆåŠŸä½†è¿˜æ²¡æœ‰éŸ³é¢‘URLï¼ˆå¯èƒ½ç”Ÿæˆä¸­ï¼‰
                        print("âš ï¸ APIå“åº”æš‚æ— éŸ³é¢‘URLï¼Œå¯èƒ½ä»åœ¨ç”Ÿæˆä¸­ï¼Œä½¿ç”¨æœ¬åœ°ç®—æ³•")
                        audio_array, sample_rate, params = generate_enhanced_therapy_audio_fast(
                            duration=duration, 
                            emotion=detected_emotion
                        )
                        audio_source = "APIç”Ÿæˆä¸­ï¼Œä¸´æ—¶æœ¬åœ°ç®—æ³•"
                        
                except Exception as e:
                    print(f"âš ï¸ å¤„ç†APIå“åº”æ—¶å‡ºé”™: {e}")
                    import traceback
                    traceback.print_exc()
                    audio_array, sample_rate, params = generate_enhanced_therapy_audio_fast(
                        duration=duration, 
                        emotion=detected_emotion
                    )
                    audio_source = "APIå¤„ç†å‡ºé”™ï¼Œæœ¬åœ°ç”Ÿæˆ"
        else:
            # ä½¿ç”¨æœ¬åœ°å¢å¼ºç®—æ³•
            audio_array, sample_rate, params = generate_enhanced_therapy_audio_fast(
                duration=duration, 
                emotion=detected_emotion
            )
            audio_source = "æœ¬åœ°å¢å¼ºç®—æ³•"
        
        # 3. ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶ï¼ˆå¢å¼ºç‰ˆï¼‰
        print(f"ğŸ” éŸ³é¢‘æ•°ç»„å½¢çŠ¶: {audio_array.shape}, é‡‡æ ·ç‡: {sample_rate}")
        print(f"ğŸ” éŸ³é¢‘æ•°ç»„ç±»å‹: {type(audio_array)}, æ•°æ®ç±»å‹: {audio_array.dtype}")
        
        try:
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
                audio_file = tmp_file.name
                print(f"ğŸ” ä¸´æ—¶æ–‡ä»¶è·¯å¾„: {audio_file}")
            
            # å°è¯•ä¿å­˜éŸ³é¢‘
            try:
                import soundfile as sf
                sf.write(audio_file, audio_array, sample_rate)
                print(f"âœ… soundfileä¿å­˜æˆåŠŸ: {audio_file}")
            except ImportError:
                print("âš ï¸ soundfileä¸å¯ç”¨ï¼Œä½¿ç”¨scipy...")
                from scipy.io import wavfile
                audio_int = (audio_array * 32767).astype(np.int16)
                wavfile.write(audio_file, sample_rate, audio_int)
                print(f"âœ… scipyä¿å­˜æˆåŠŸ: {audio_file}")
            
            # éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§å’Œå¤§å°
            import os
            if os.path.exists(audio_file):
                file_size = os.path.getsize(audio_file)
                print(f"âœ… æ–‡ä»¶éªŒè¯æˆåŠŸ: {audio_file} ({file_size} bytes)")
                if file_size == 0:
                    raise Exception("éŸ³é¢‘æ–‡ä»¶å¤§å°ä¸º0")
            else:
                raise Exception(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
                
        except Exception as e:
            print(f"âŒ éŸ³é¢‘ä¿å­˜å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return f"âŒ éŸ³é¢‘ä¿å­˜å¤±è´¥: {e}", None, "ä¿å­˜å¤±è´¥"
        
        processing_time = time.time() - start_time
        
        # 4. ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šï¼ˆé›†æˆSuno APIä¿¡æ¯ï¼‰
        # è·å–éŸ³ä¹ç‰¹å¾ä¿¡æ¯
        music_features = get_emotion_music_features(detected_emotion)
        
        report = f"""âœ… å¢å¼ºä¸‰é˜¶æ®µç–—æ„ˆéŸ³é¢‘ç”Ÿæˆå®Œæˆï¼

ğŸ§  æƒ…ç»ªè¯†åˆ«ç»“æœ:
   â€¢ æ£€æµ‹æƒ…ç»ª: {detected_emotion}
   â€¢ ç½®ä¿¡åº¦: {confidence:.1%}
   â€¢ å¤„ç†æ—¶é—´: {processing_time:.1f}ç§’
   â€¢ éŸ³é¢‘æ¥æº: {audio_source}

ğŸµ éŸ³é¢‘æŠ€æœ¯å‚æ•°:
   â€¢ æ€»æ—¶é•¿: {duration}ç§’
   â€¢ é‡‡æ ·ç‡: {sample_rate}Hz
   â€¢ å£°é“: ç«‹ä½“å£°
   â€¢ é’ˆå¯¹æƒ…ç»ª: {detected_emotion}

ğŸ¼ ISOä¸‰é˜¶æ®µéŸ³ä¹ç‰¹å¾æ˜ å°„ï¼ˆç¡•å£«é¡¹ç›®æ ¸å¿ƒï¼‰:
   â€¢ åŒ¹é…é˜¶æ®µ: {music_features['åŒ¹é…é˜¶æ®µ']['tempo']}, {music_features['åŒ¹é…é˜¶æ®µ']['key']}
     â””â”€ {music_features['åŒ¹é…é˜¶æ®µ']['mood']}
   â€¢ å¼•å¯¼é˜¶æ®µ: {music_features['å¼•å¯¼é˜¶æ®µ']['tempo']}, {music_features['å¼•å¯¼é˜¶æ®µ']['key']}
     â””â”€ {music_features['å¼•å¯¼é˜¶æ®µ']['mood']}
   â€¢ ç›®æ ‡é˜¶æ®µ: {music_features['ç›®æ ‡é˜¶æ®µ']['tempo']}, {music_features['ç›®æ ‡é˜¶æ®µ']['key']}
     â””â”€ {music_features['ç›®æ ‡é˜¶æ®µ']['mood']}

ğŸŒŠ ä¸‰é˜¶æ®µæµç•…è¿‡æ¸¡:
   â€¢ åŒæ­¥æœŸ ({duration*0.3:.1f}s): {params['sync_freq']}Hz - åŒ¹é…{detected_emotion}æƒ…ç»ª
   â€¢ å¼•å¯¼æœŸ ({duration*0.4:.1f}s): {params['sync_freq']}â†’{params['guide_freq']}Hz - æµç•…è¿‡æ¸¡
   â€¢ å·©å›ºæœŸ ({duration*0.3:.1f}s): {params['consolidate_freq']}Hz - æ·±åº¦æ”¾æ¾

ğŸ¼ ç–—æ„ˆæŠ€æœ¯ç‰¹è‰²:
   â€¢ è¿‡æ¸¡ç±»å‹: {params['transition_type']} (æƒ…ç»ªä¸“å±)
   â€¢ å’Œè°æ³›éŸ³: å¢å¼ºç–—æ„ˆæ•ˆæœ
   â€¢ è‡ªç„¶éŸ³æ•ˆ: æµ·æµªå£° + ç¯å¢ƒéŸ³
   â€¢ ç«‹ä½“å£°åœº: 5mså»¶è¿Ÿ + ç©ºé—´æ„Ÿ
   â€¢ æ·¡å…¥æ·¡å‡º: 0.2ç§’å¹³æ»‘è¿‡æ¸¡

ğŸ’° æˆæœ¬æ§åˆ¶çŠ¶æ€:
   â€¢ APIçŠ¶æ€: {'å¼€å¯' if SUNO_API_ENABLED else 'å…³é—­'}
   â€¢ æµ‹è¯•æ¨¡å¼: {'æ˜¯' if TEST_MODE else 'å¦'}
   â€¢ ä»Šæ—¥è°ƒç”¨: {daily_call_count}/{MAX_DAILY_CALLS}

ğŸ§ ä½¿ç”¨å»ºè®®:
   â€¢ ä½©æˆ´è€³æœºè·å¾—æœ€ä½³ç«‹ä½“å£°æ•ˆæœ
   â€¢ åœ¨å®‰é™ç¯å¢ƒä¸­è†å¬
   â€¢ è·ŸéšéŸ³é¢‘èŠ‚å¥è°ƒæ•´å‘¼å¸
   â€¢ ä¸“æ³¨æ„Ÿå—ä¸‰é˜¶æ®µæƒ…ç»ªè½¬æ¢

ğŸŒŸ æ ¸å¿ƒåˆ›æ–°:
   â€¢ æµç•…è¿‡æ¸¡: æ•°å­¦ç²¾ç¡®çš„æ— ç¼åˆ‡æ¢
   â€¢ æƒ…ç»ªæ˜ å°„: {detected_emotion}æƒ…ç»ªçš„ä¸“å±å‚æ•°
   â€¢ ç–—æ„ˆå™äº‹: è¿è´¯çš„æƒ…ç»ªè½¬æ¢æ•…äº‹
   â€¢ å­¦æœ¯ç†è®º: ISOä¸‰é˜¶æ®µåŸåˆ™åº”ç”¨
   â€¢ APIé›†æˆ: çœŸå®AIéŸ³ä¹ç”Ÿæˆèƒ½åŠ›

ğŸŒ™ ç°åœ¨è¯·æˆ´ä¸Šè€³æœºï¼Œä½“éªŒçœŸæ­£çš„æµç•…è¿‡æ¸¡ç–—æ„ˆæ•ˆæœï¼"""
        
        # æœ€ç»ˆéªŒè¯å’Œè¿”å›
        import os
        print(f"ğŸ” è¿”å›çš„audio_file: {audio_file}")
        print(f"ğŸ” æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {os.path.exists(audio_file) if 'audio_file' in locals() else 'audio_fileæœªå®šä¹‰'}")
        
        return report, audio_file, f"æˆåŠŸç”Ÿæˆ{detected_emotion}ç–—æ„ˆéŸ³é¢‘ - {audio_source}"
        
    except Exception as e:
        import traceback
        error_msg = f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}"
        print(error_msg)
        traceback.print_exc()
        return error_msg, None, "ç”Ÿæˆå¤±è´¥"

def load_previous_suno_music():
    """åŠ è½½ä¹‹å‰æˆåŠŸç”Ÿæˆçš„SunoéŸ³ä¹"""
    # ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œå…¼å®¹ä¸åŒç³»ç»Ÿ
    import os
    current_dir = os.path.dirname(os.path.abspath(__file__))
    audio_file_path = os.path.join(current_dir, "previous_suno_fdd1b90b.mp3")
    
    if os.path.exists(audio_file_path):
        report = f"""ğŸµ æˆåŠŸåŠ è½½ä¹‹å‰çš„Suno AIéŸ³ä¹ï¼

ğŸ¼ éŸ³ä¹ä¿¡æ¯:
   â€¢ æ ‡é¢˜: "Whisper of the Moon"
   â€¢ æ—¶é•¿: çº¦2åˆ†44ç§’ (164ç§’)
   â€¢ æ¨¡å‹: å·²ä¿®å¤ä¸ºChirp-v3 (æˆæœ¬ä¼˜åŒ–)
   â€¢ é£æ ¼: å®é™ç¡çœ éŸ³ä¹
   â€¢ æ ‡ç­¾: sleep, soft, acoustic, soothing
   
ğŸ¹ éŸ³ä¹ç‰¹è‰²:
   â€¢ æŒ‡å¼¹å‰ä»–ä¸æ¸©æŸ”é’¢ç´å’Œå¼¦
   â€¢ ç¯å¢ƒå¼¦ä¹çš„å¾®å¦™å—¡é¸£å£°
   â€¢ å¤šå±‚æ¬¡æŸ”å’ŒéŸ³å“
   â€¢ ä¸“ä¸ºç¡å‰æ”¾æ¾è®¾è®¡
   
ğŸŒ™ ç–—æ„ˆæ•ˆæœ:
   â€¢ æ·±åº¦æ”¾æ¾: acoustic fingerpickingè¥é€ å®‰å…¨æ„Ÿ
   â€¢ æƒ…ç»ªç¨³å®š: æ¸©å’Œçš„é’¢ç´å’Œå¼¦å¸¦æ¥å¹³é™
   â€¢ åŠ©çœ å¼•å¯¼: ç¯å¢ƒéŸ³æ•ˆå¸®åŠ©å¤§è„‘æ”¾æ¾
   â€¢ æŒç»­ç–—æ„ˆ: 2åˆ†44ç§’å®Œæ•´çš„æ”¾æ¾ä½“éªŒ
   
ğŸ§ ä½¿ç”¨å»ºè®®:
   â€¢ ä½©æˆ´è€³æœºè·å¾—æœ€ä½³ç«‹ä½“å£°æ•ˆæœ
   â€¢ è°ƒè‡³èˆ’é€‚éŸ³é‡ (å»ºè®®50-70%)
   â€¢ åœ¨å®‰é™ç¯å¢ƒä¸­è†å¬
   â€¢ é—­çœ¼è·ŸéšéŸ³ä¹è¿›å…¥æ”¾æ¾çŠ¶æ€
   
âœ¨ è¿™æ˜¯çœŸå®çš„Suno AIç”ŸæˆéŸ³ä¹ï¼Œå±•ç¤ºäº†AIéŸ³ä¹ç–—æ„ˆçš„å®é™…æ•ˆæœï¼
ğŸŒŸ ä»»åŠ¡ID: fdd1b90b-47e2-44ca-a3b9-8b7ff83554dc"""
        
        return report, audio_file_path, "âœ… æˆåŠŸåŠ è½½ä¹‹å‰çš„SunoéŸ³ä¹"
    else:
        return "âŒ æœªæ‰¾åˆ°ä¹‹å‰çš„éŸ³ä¹æ–‡ä»¶", None, "âŒ æ–‡ä»¶ä¸å­˜åœ¨"

def create_therapy_interface():
    """åˆ›å»ºç–—æ„ˆç•Œé¢"""
    # è‡ªå®šä¹‰CSSæ ·å¼
    css = """
    .therapy-container {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
        border-radius: 15px;
        color: white;
        text-align: center;
        margin-bottom: 20px;
    }
    .therapy-title {
        font-size: 24px;
        font-weight: bold;
        margin-bottom: 10px;
    }
    .therapy-subtitle {
        font-size: 16px;
        opacity: 0.9;
    }
    .therapy-highlight {
        background: #ffeb3b;
        color: #333;
        padding: 5px 10px;
        border-radius: 5px;
        font-weight: bold;
    }
    """
    
    with gr.Blocks(title="ğŸŒ™ å¢å¼ºä¸‰é˜¶æ®µç–—æ„ˆç³»ç»Ÿ") as app:
        
        # æ ‡é¢˜åŒºåŸŸ
        gr.HTML("""
        <div class="therapy-container">
            <div class="therapy-title">ğŸŒ™ å¢å¼ºä¸‰é˜¶æ®µç–—æ„ˆç³»ç»Ÿ</div>
            <div class="therapy-subtitle">ç«¯åˆ°ç«¯å®Œæ•´ä½“éªŒï¼šè¾“å…¥æƒ…ç»ª â†’ æ™ºèƒ½ç”Ÿæˆ â†’ å³æ—¶æ’­æ”¾</div>
            <div style="margin-top: 10px;">
                <span class="therapy-highlight">âœ¨ çœŸæ­£çš„æµç•…è¿‡æ¸¡ + å®Œç¾éŸ³ç”»åŒæ­¥</span>
            </div>
        </div>
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ’­ æƒ…ç»ªè¾“å…¥")
                
                # å¿«é€Ÿæƒ…ç»ªé€‰æ‹©
                emotion_examples = gr.Dropdown(
                    choices=[
                        "ğŸ˜° æˆ‘æ„Ÿåˆ°å¾ˆç„¦è™‘ï¼Œå¿ƒè·³åŠ é€Ÿï¼Œéš¾ä»¥å…¥ç¡",
                        "ğŸ˜´ æˆ‘å¾ˆç–²æƒ«ï¼Œä½†å¤§è„‘è¿˜åœ¨æ´»è·ƒï¼Œæ— æ³•æ”¾æ¾",
                        "ğŸ˜¤ æˆ‘æ„Ÿåˆ°çƒ¦èºä¸å®‰ï¼Œå®¹æ˜“è¢«å°äº‹å½±å“",
                        "ğŸ˜Œ æˆ‘æ¯”è¾ƒå¹³é™ï¼Œä½†å¸Œæœ›æ›´æ·±å±‚çš„æ”¾æ¾",
                        "ğŸ¤¯ æœ€è¿‘å‹åŠ›å¾ˆå¤§ï¼Œæ€»æ˜¯æ„Ÿåˆ°ç´§å¼ "
                    ],
                    label="ğŸ­ å¿«é€Ÿé€‰æ‹©æƒ…ç»ª",
                    value="ğŸ˜° æˆ‘æ„Ÿåˆ°å¾ˆç„¦è™‘ï¼Œå¿ƒè·³åŠ é€Ÿï¼Œéš¾ä»¥å…¥ç¡"
                )
                
                # è¯¦ç»†æƒ…ç»ªæè¿°
                emotion_input = gr.Textbox(
                    label="âœï¸ è¯¦ç»†æè¿°æ‚¨çš„æƒ…ç»ªçŠ¶æ€",
                    placeholder="è¯·è¯¦ç»†æè¿°æ‚¨å½“å‰çš„æƒ…ç»ªæ„Ÿå—...",
                    lines=3,
                    value="æˆ‘æ„Ÿåˆ°å¾ˆç„¦è™‘ï¼Œå¿ƒè·³åŠ é€Ÿï¼Œéš¾ä»¥å…¥ç¡"
                )
                
                # ç–—æ„ˆæ—¶é•¿
                duration_slider = gr.Slider(
                    minimum=5, 
                    maximum=20, 
                    value=12, 
                    step=1,
                    label="â±ï¸ ç–—æ„ˆæ—¶é•¿ï¼ˆç§’ï¼‰",
                    info="æ¨è12-15ç§’è·å¾—æœ€ä½³ä½“éªŒ"
                )
                
                # Suno APIé€‰é¡¹
                with gr.Row():
                    use_suno = gr.Checkbox(
                        label="ğŸµ ä½¿ç”¨Suno AIéŸ³ä¹ç”Ÿæˆ",
                        value=False,
                        info="å¯ç”¨çœŸå®AIéŸ³ä¹ï¼ˆæµ‹è¯•æ¨¡å¼ä¸‹å®‰å…¨ï¼‰"
                    )
                    enable_real_api = gr.Checkbox(
                        label="ğŸ’° å¯ç”¨çœŸå®APIè°ƒç”¨",
                        value=False,
                        info="âš ï¸ éœ€è¦æ¶ˆè€—APIè´¹ç”¨ï¼"
                    )
                
                # ç°æœ‰ä»»åŠ¡IDè¾“å…¥ï¼ˆé¿å…é‡å¤è°ƒç”¨ï¼‰
                existing_task_input = gr.Textbox(
                    label="ğŸ”„ ä½¿ç”¨ç°æœ‰ä»»åŠ¡IDï¼ˆé¿å…é‡å¤è°ƒç”¨ï¼‰",
                    placeholder="ä¾‹å¦‚: fdd1b90b-47e2-44ca-a3b9-8b7ff83554dc",
                    value="",
                    info="å¦‚æœæœ‰ä¹‹å‰çš„ä»»åŠ¡IDï¼Œå¯ä»¥ç›´æ¥è·å–ç»“æœï¼Œé¿å…é‡æ–°æ¶ˆè€—API"
                )
                
                # å¿«é€Ÿæ’­æ”¾å·²æœ‰éŸ³ä¹
                with gr.Row():
                    load_previous_btn = gr.Button(
                        "ğŸµ æ’­æ”¾ä¹‹å‰æˆåŠŸç”Ÿæˆçš„SunoéŸ³ä¹",
                        variant="secondary"
                    )
                
                # ç”ŸæˆæŒ‰é’®
                generate_btn = gr.Button(
                    "ğŸŒŠ å¼€å§‹å¢å¼ºä¸‰é˜¶æ®µç–—æ„ˆ",
                    variant="primary",
                    size="lg"
                )
                
                # ç³»ç»Ÿè¯´æ˜
                gr.HTML("""
                <div style="margin-top: 20px; padding: 15px; background: rgba(255,255,255,0.1); border-radius: 10px;">
                    <strong>ğŸŒŠ å¢å¼ºä¸‰é˜¶æ®µç–—æ„ˆåŸç†ï¼š</strong><br>
                    <div style="margin-top: 10px; text-align: left;">
                        <div><strong>ğŸ¯ åŒæ­¥æœŸ (30%)</strong>: åŒ¹é…æ‚¨çš„æƒ…ç»ªé¢‘ç‡</div>
                        <div><strong>ğŸŒ€ å¼•å¯¼æœŸ (40%)</strong>: æµç•…è¿‡æ¸¡åˆ°æ”¾æ¾çŠ¶æ€</div>
                        <div><strong>ğŸ’¤ å·©å›ºæœŸ (30%)</strong>: æ·±åº¦æ”¾æ¾ï¼Œå‡†å¤‡å…¥ç¡</div>
                    </div>
                    <div style="margin-top: 10px; font-size: 14px; opacity: 0.8;">
                        âœ¨ ç‰¹è‰²ï¼šæ•°å­¦ç²¾ç¡®çš„æ— ç¼è¿‡æ¸¡ + æƒ…ç»ªä¸“å±å‚æ•°
                    </div>
                    <div style="margin-top: 10px; padding: 10px; background: rgba(255,215,0,0.2); border-radius: 5px;">
                        <strong>ğŸµ Suno AIé›†æˆï¼š</strong><br>
                        <div style="font-size: 12px; margin-top: 5px;">
                            â€¢ <strong>æµ‹è¯•æ¨¡å¼</strong>ï¼šå®‰å…¨æ¨¡æ‹Ÿï¼Œæ— è´¹ç”¨<br>
                            â€¢ <strong>çœŸå®æ¨¡å¼</strong>ï¼šæ¶ˆè€—APIè´¹ç”¨ï¼Œéœ€è°¨æ…<br>
                            â€¢ <strong>æˆæœ¬æ§åˆ¶</strong>ï¼šæ¯æ—¥æœ€å¤š3æ¬¡è°ƒç”¨<br>
                            â€¢ <strong>ğŸµ å¿«é€Ÿä½“éªŒ</strong>ï¼šç‚¹å‡»æŒ‰é’®æ’­æ”¾ä¹‹å‰æˆåŠŸç”Ÿæˆçš„çœŸå®AIéŸ³ä¹ï¼
                        </div>
                    </div>
                </div>
                """)
            
            with gr.Column(scale=2):
                gr.Markdown("### ğŸ¬ ç–—æ„ˆä½“éªŒ")
                
                # è¯¦ç»†ä¿¡æ¯æ˜¾ç¤º
                info_output = gr.Textbox(
                    label="ğŸ“Š ç–—æ„ˆç”ŸæˆæŠ¥å‘Š",
                    lines=25,
                    interactive=False,
                    value="ç­‰å¾…æ‚¨çš„æƒ…ç»ªè¾“å…¥ï¼Œå¼€å§‹ä¸ªæ€§åŒ–ç–—æ„ˆä½“éªŒ..."
                )
                
                # éŸ³é¢‘æ’­æ”¾å™¨
                audio_output = gr.Audio(
                    label="ğŸµ ä¸‰é˜¶æ®µç–—æ„ˆéŸ³é¢‘",
                    type="filepath",
                    interactive=True
                )
                
                # çŠ¶æ€æ˜¾ç¤º
                status_output = gr.Textbox(
                    label="ğŸ”„ å¤„ç†çŠ¶æ€",
                    interactive=False,
                    value="å°±ç»ª"
                )
        
        # ä½¿ç”¨æŒ‡å—
        gr.HTML("""
        <div style="margin-top: 20px; padding: 20px; background: #f8f9fa; border-radius: 10px;">
            <h3 style="color: #333;">ğŸ¯ å®Œæ•´ä½¿ç”¨æŒ‡å—</h3>
            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin-top: 15px;">
                <div>
                    <h4 style="color: #555;">ğŸµ éŸ³é¢‘ä½“éªŒ</h4>
                    <ul style="color: #666; text-align: left;">
                        <li>ä½©æˆ´è€³æœºè·å¾—æœ€ä½³ç«‹ä½“å£°æ•ˆæœ</li>
                        <li>åœ¨å®‰é™ç¯å¢ƒä¸­è†å¬</li>
                        <li>éŸ³é‡è°ƒè‡³èˆ’é€‚æ°´å¹³</li>
                        <li>ä¸“æ³¨æ„Ÿå—ä¸‰é˜¶æ®µè½¬æ¢</li>
                    </ul>
                </div>
                <div>
                    <h4 style="color: #555;">ğŸ§˜ ç–—æ„ˆè¿‡ç¨‹</h4>
                    <ul style="color: #666; text-align: left;">
                        <li>è·ŸéšéŸ³é¢‘èŠ‚å¥è°ƒæ•´å‘¼å¸</li>
                        <li>è®©éŸ³ä¹å¼•å¯¼æ‚¨çš„æƒ…ç»ª</li>
                        <li>æ„Ÿå—ä»ç´§å¼ åˆ°æ”¾æ¾çš„è¿‡æ¸¡</li>
                        <li>äº«å—æœ€ç»ˆçš„æ·±åº¦å¹³é™</li>
                    </ul>
                </div>
                <div>
                    <h4 style="color: #555;">ğŸŒŸ æŠ€æœ¯ç‰¹è‰²</h4>
                    <ul style="color: #666; text-align: left;">
                        <li>5ç§æƒ…ç»ªçš„ä¸“å±å‚æ•°è®¾è®¡</li>
                        <li>4ç§æ•°å­¦è¿‡æ¸¡å‡½æ•°</li>
                        <li>ç«‹ä½“å£°ç©ºé—´åŒ–å¤„ç†</li>
                        <li>è‡ªç„¶éŸ³æ•ˆèåˆ</li>
                    </ul>
                </div>
            </div>
        </div>
        """)
        
        # äº‹ä»¶ç»‘å®š
        def update_input_from_dropdown(selected):
            if " " in selected:
                return selected.split(" ", 1)[1]
            return selected
        
        emotion_examples.change(
            update_input_from_dropdown,
            inputs=emotion_examples,
            outputs=emotion_input
        )
        
        generate_btn.click(
            process_therapy_request,
            inputs=[emotion_input, duration_slider, use_suno, enable_real_api, existing_task_input],
            outputs=[info_output, audio_output, status_output]
        )
        
        load_previous_btn.click(
            load_previous_suno_music,
            inputs=[],
            outputs=[info_output, audio_output, status_output]
        )
    
    return app

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨å¢å¼ºä¸‰é˜¶æ®µç–—æ„ˆç³»ç»Ÿ - å®Œæ•´Webç•Œé¢")
    print("ğŸŒŠ ç«¯åˆ°ç«¯ä½“éªŒï¼šè¾“å…¥æƒ…ç»ª â†’ æ™ºèƒ½ç”Ÿæˆ â†’ å³æ—¶æ’­æ”¾")
    print("âœ¨ ç‰¹è‰²ï¼šæµç•…è¿‡æ¸¡ + å®Œç¾éŸ³ç”»åŒæ­¥")
    print("ğŸ¯ è®¿é—®åœ°å€å³å°†æ˜¾ç¤º...")
    
    app = create_therapy_interface()
    app.launch(
        server_name="0.0.0.0",
        server_port=7869,
        share=True
    )

if __name__ == "__main__":
    main()